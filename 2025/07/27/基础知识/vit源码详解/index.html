<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>vit源码详解(linformer) | Sunhanyu-Learning</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="1.环境安装➕训练 下载transformer，vit-pytorch两个代码仓.   123git clone git@github.com:huggingface&#x2F;transformers.gitgit clone git@github.com:lucidrains&#x2F;vit-pytorch.git分别使用 pip install -e . 可以安装上述两个代码仓 vit-pytorch&#x2F;exa">
<meta property="og:type" content="article">
<meta property="og:title" content="vit源码详解(linformer)">
<meta property="og:url" content="http://example.com/2025/07/27/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/vit%E6%BA%90%E7%A0%81%E8%AF%A6%E8%A7%A3/index.html">
<meta property="og:site_name" content="Sunhanyu-Learning">
<meta property="og:description" content="1.环境安装➕训练 下载transformer，vit-pytorch两个代码仓.   123git clone git@github.com:huggingface&#x2F;transformers.gitgit clone git@github.com:lucidrains&#x2F;vit-pytorch.git分别使用 pip install -e . 可以安装上述两个代码仓 vit-pytorch&#x2F;exa">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/jpg/onnx-vit.jpg">
<meta property="article:published_time" content="2025-07-26T16:00:00.000Z">
<meta property="article:modified_time" content="2025-07-28T05:54:39.656Z">
<meta property="article:author" content="sunhanyu">
<meta property="article:tag" content="vit">
<meta property="article:tag" content="Transformer">
<meta property="article:tag" content="linformer">
<meta property="article:tag" content="vit-pytorch">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/jpg/onnx-vit.jpg">
  
    <link rel="alternate" href="/atom.xml" title="Sunhanyu-Learning" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/fork-awesome@1.2.0/css/fork-awesome.min.css">

<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Sunhanyu-Learning</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-基础知识/vit源码详解" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/07/27/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/vit%E6%BA%90%E7%A0%81%E8%AF%A6%E8%A7%A3/" class="article-date">
  <time class="dt-published" datetime="2025-07-26T16:00:00.000Z" itemprop="datePublished">2025-07-27</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/">基础知识</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      vit源码详解(linformer)
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="1-环境安装➕训练"><a href="#1-环境安装➕训练" class="headerlink" title="1.环境安装➕训练"></a>1.环境安装➕训练</h1><ul>
<li><p>下载transformer，vit-pytorch两个代码仓.</p>
  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> git@github.com:huggingface/transformers.git</span><br><span class="line">git <span class="built_in">clone</span> git@github.com:lucidrains/vit-pytorch.git</span><br><span class="line">分别使用 pip install -e . 可以安装上述两个代码仓</span><br></pre></td></tr></table></figure></li>
<li><p><code>vit-pytorch/examples/cats_and_dogs.ipynb</code>按照内部说明下载<code>data</code>。</p>
</li>
<li><p>修改jupyter最后一步的训练代码如下，保存最优模型。</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">best_val_acc = <span class="number">0</span></span><br><span class="line">save_path = <span class="string">&quot;model/best_model_vit.pth&quot;</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    epoch_loss = <span class="number">0</span></span><br><span class="line">    epoch_accuracy = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> data, label <span class="keyword">in</span> tqdm(train_loader):</span><br><span class="line">        data = data.to(device)</span><br><span class="line">        label = label.to(device)</span><br><span class="line"></span><br><span class="line">        output = model(data)</span><br><span class="line">        loss = criterion(output, label)</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        acc = (output.argmax(dim=<span class="number">1</span>) == label).<span class="built_in">float</span>().mean()</span><br><span class="line">        epoch_accuracy += acc / <span class="built_in">len</span>(train_loader)</span><br><span class="line">        epoch_loss += loss / <span class="built_in">len</span>(train_loader)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        epoch_val_accuracy = <span class="number">0</span></span><br><span class="line">        epoch_val_loss = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> data, label <span class="keyword">in</span> valid_loader:</span><br><span class="line">            data = data.to(device)</span><br><span class="line">            label = label.to(device)</span><br><span class="line"></span><br><span class="line">            val_output = model(data)</span><br><span class="line">            val_loss = criterion(val_output, label)</span><br><span class="line"></span><br><span class="line">            acc = (val_output.argmax(dim=<span class="number">1</span>) == label).<span class="built_in">float</span>().mean()</span><br><span class="line">            epoch_val_accuracy += acc / <span class="built_in">len</span>(valid_loader)</span><br><span class="line">            epoch_val_loss += val_loss / <span class="built_in">len</span>(valid_loader)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># ✅ 5. 模型保存（val acc 最优）</span></span><br><span class="line">    <span class="keyword">if</span> epoch_val_accuracy &gt; best_val_acc:</span><br><span class="line">        torch.save(model.state_dict(), save_path)</span><br><span class="line">        best_val_acc = epoch_val_accuracy</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(</span><br><span class="line">        <span class="string">f&quot;Epoch : <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span> - loss : <span class="subst">&#123;epoch_loss:<span class="number">.4</span>f&#125;</span> - acc: <span class="subst">&#123;epoch_accuracy:<span class="number">.4</span>f&#125;</span> - val_loss : <span class="subst">&#123;epoch_val_loss:<span class="number">.4</span>f&#125;</span> - val_acc: <span class="subst">&#123;epoch_val_accuracy:<span class="number">.4</span>f&#125;</span>\n&quot;</span></span><br><span class="line">    )</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>运行jupyter，得到最终模型<code>best_model_vit.pth</code>。</p>
</li>
</ul>
<h1 id="2-源码解读"><a href="#2-源码解读" class="headerlink" title="2.源码解读"></a>2.源码解读</h1><ul>
<li>总数据流  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">image → patch → embedding → +CLS → +PE</span><br><span class="line">    ↓</span><br><span class="line">Transformer encoder</span><br><span class="line">    ↓</span><br><span class="line">取 [CLS] or Mean</span><br><span class="line">    ↓</span><br><span class="line">Linear → MLP head → 分类 logits </span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="2-1-数据预处理"><a href="#2-1-数据预处理" class="headerlink" title="2.1 数据预处理"></a>2.1 数据预处理</h2><ul>
<li>将一张图片从 [batch, channel, height, width] 转换为 [batch, num_patches, dim] 的形式  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">image_height, image_width = pair(image_size)<span class="comment">#原始图片大小</span></span><br><span class="line">patch_height, patch_width = pair(patch_size)<span class="comment">#每个patch的长宽</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">assert</span> image_height % patch_height == <span class="number">0</span> <span class="keyword">and</span> image_width % patch_width == <span class="number">0</span>, <span class="string">&#x27;Image dimensions must be divisible by the patch size.&#x27;</span></span><br><span class="line"></span><br><span class="line">num_patches = (image_height // patch_height) * (image_width // patch_width) <span class="comment">#一张图片被分为多少个patch</span></span><br><span class="line">patch_dim = channels * patch_height * patch_width <span class="comment">#每个patch的维度</span></span><br><span class="line"><span class="keyword">assert</span> pool <span class="keyword">in</span> &#123;<span class="string">&#x27;cls&#x27;</span>, <span class="string">&#x27;mean&#x27;</span>&#125;, <span class="string">&#x27;pool type must be either cls (cls token) or mean (mean pooling)&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="variable language_">self</span>.to_patch_embedding = nn.Sequential(</span><br><span class="line">            Rearrange(<span class="string">&#x27;b c (h p1) (w p2) -&gt; b (h w) (p1 p2 c)&#x27;</span>, p1 = patch_height, p2 = patch_width),</span><br><span class="line">            nn.LayerNorm(patch_dim),</span><br><span class="line">            nn.Linear(patch_dim, dim),</span><br><span class="line">            nn.LayerNorm(dim),</span><br><span class="line">            )<span class="comment">## img转换成patch后经过embedding变成[batch,num_patchs,dim]大小的数据</span></span><br></pre></td></tr></table></figure></li>
<li>forward如下：  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x = <span class="variable language_">self</span>.to_patch_embedding(img)<span class="comment">#img 按照切块儿的方式转换成embedding</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="2-2-数据embedding-post-embedding"><a href="#2-2-数据embedding-post-embedding" class="headerlink" title="2.2 数据embedding + post embedding"></a>2.2 数据embedding + post embedding</h2><ul>
<li><p>init</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">输入：              patch_1  patch_2  ...  patch_n</span><br><span class="line">                    ↓        ↓             ↓</span><br><span class="line">拼接：    [CLS]    patch_1  patch_2  ...  patch_n</span><br><span class="line">            ↓        ↓        ↓             ↓</span><br><span class="line">位置编码： +PE_0    +PE_1    +PE_2        +PE_n</span><br><span class="line">            ↓        ↓        ↓             ↓</span><br><span class="line">输入：  [CLS+PE_0, patch_1+PE_1, ..., patch_n+PE_n]</span><br><span class="line"></span><br><span class="line"><span class="variable language_">self</span>.pos_embedding = nn.Parameter(torch.randn(<span class="number">1</span>, num_patches + <span class="number">1</span>, dim)) <span class="comment">#+1，是因为还要加上一个 [CLS] token；dim通常为768</span></span><br><span class="line"><span class="variable language_">self</span>.cls_token = nn.Parameter(torch.randn(<span class="number">1</span>, <span class="number">1</span>, dim))<span class="comment">#这是 ViT 模仿 NLP 中 BERT 的做法，在最前面添加一个“全局摘要”用的 token。</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>forward如下：</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">b, n, _ = x.shape</span><br><span class="line"></span><br><span class="line">cls_tokens = repeat(<span class="variable language_">self</span>.cls_token, <span class="string">&#x27;1 1 d -&gt; b 1 d&#x27;</span>, b = b)</span><br><span class="line">x = torch.cat((cls_tokens, x), dim=<span class="number">1</span>) <span class="comment">#把 [CLS] token 拼接到每个图像 patch 序列的最前面。</span></span><br><span class="line">x += <span class="variable language_">self</span>.pos_embedding[:, :(n + <span class="number">1</span>)] <span class="comment">#给每个 patch + [CLS] token 加上对应的 位置编码；</span></span><br><span class="line">x = <span class="variable language_">self</span>.dropout(x) <span class="comment">#提高泛化能力，防止过拟合。</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="2-3-transformer"><a href="#2-3-transformer" class="headerlink" title="2.3 transformer"></a>2.3 transformer</h2><ul>
<li>transformer结构<ul>
<li><p><code>layers = [ (PreNorm(attn_1), PreNorm(ff_1)), (PreNorm(attn_2), PreNorm(ff_2)), ... ]   </code><br>这个是layer的结构，每个结构之前先过一个prenorm，<code>x = self.norm(x) return self.fn(x)</code><br>整体数据流如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">SequentialSequence：x = x + attn(x) x = x + ffn(x)</span><br><span class="line"><span class="built_in">input</span> x</span><br><span class="line">↓</span><br><span class="line">(attn_1 → ff_1) <span class="keyword">with</span> residual</span><br><span class="line">↓</span><br><span class="line">(attn_2 → ff_2)</span><br><span class="line">↓</span><br><span class="line">...</span><br><span class="line">↓</span><br><span class="line">(attn_n → ff_n)</span><br><span class="line">↓</span><br><span class="line">output</span><br><span class="line"></span><br><span class="line"><span class="comment">##树形数据流</span></span><br><span class="line">Transformer Block</span><br><span class="line">├── Multi-Head Attention</span><br><span class="line">│    └── Residual + LayerNorm</span><br><span class="line">├── FeedForward</span><br><span class="line">│    ├── Linear1 (dim → dim*<span class="number">4</span>)</span><br><span class="line">│    ├── GELU</span><br><span class="line">│    ├── Dropout</span><br><span class="line">│    ├── Linear2 (dim*<span class="number">4</span> → dim)</span><br><span class="line">│    └── Residual + LayerNorm</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Linformer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, seq_len, depth, k = <span class="number">256</span>, heads = <span class="number">8</span>, dim_head = <span class="literal">None</span>, one_kv_head = <span class="literal">False</span>, share_kv = <span class="literal">False</span>, reversible = <span class="literal">False</span>, dropout = <span class="number">0.</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        layers = nn.ModuleList([])</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(depth):</span><br><span class="line">            attn = LinformerSelfAttention(dim, seq_len, k = k, heads = heads, dim_head = dim_head, one_kv_head = one_kv_head, share_kv = share_kv, dropout = dropout)</span><br><span class="line">            ff = FeedForward(dim, dropout = dropout)</span><br><span class="line"></span><br><span class="line">            layers.append(nn.ModuleList([</span><br><span class="line">                PreNorm(dim, attn),</span><br><span class="line">                PreNorm(dim, ff)</span><br><span class="line">            ]))</span><br><span class="line"></span><br><span class="line">        execute_type = ReversibleSequence <span class="keyword">if</span> reversible <span class="keyword">else</span> SequentialSequence</span><br><span class="line">        <span class="variable language_">self</span>.net = execute_type(layers)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.net(x)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>attention结构<ul>
<li>linformer通过低秩空间的映射，使其从 O(n²) 降为 O(n·k)，其中 k ≪ n。主要结构为Proj_k。</li>
<li>linformer结构数据流如下：             <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">     ↓ to_q (Linear)</span><br><span class="line">Input x ───────────────→ Q</span><br><span class="line">      ↓ to_k/v (Linear)</span><br><span class="line">Input x ───────────────→ K, V → einsum(Proj_k/v) → K_proj, V_proj</span><br><span class="line">      ↓</span><br><span class="line"> Multi-head Attention</span><br><span class="line">      ↓</span><br><span class="line">   Output (Linear)</span><br></pre></td></tr></table></figure></li>
<li><code>self.proj_k = nn.Parameter(init_(torch.zeros(seq_len, k)))</code><br>proj_k: 是形状 [seq_len, k] 的 learnable 参数；<br>用于将原始 Key&#x2F;Value 沿着序列维度投影到更低维空间（线性投影矩阵）；也就是减少seq_len的维度</li>
<li>代码如下：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LinformerSelfAttention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, seq_len, k = <span class="number">256</span>, heads = <span class="number">8</span>, dim_head = <span class="literal">None</span>, one_kv_head = <span class="literal">False</span>, share_kv = <span class="literal">False</span>, dropout = <span class="number">0.</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="keyword">assert</span> (dim % heads) == <span class="number">0</span>, <span class="string">&#x27;dimension must be divisible by the number of heads&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.seq_len = seq_len</span><br><span class="line">        <span class="variable language_">self</span>.k = k</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.heads = heads</span><br><span class="line"></span><br><span class="line">        dim_head = default(dim_head, dim // heads)</span><br><span class="line">        <span class="variable language_">self</span>.dim_head = dim_head</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.to_q = nn.Linear(dim, dim_head * heads, bias = <span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        kv_dim = dim_head <span class="keyword">if</span> one_kv_head <span class="keyword">else</span> (dim_head * heads)</span><br><span class="line">        <span class="variable language_">self</span>.to_k = nn.Linear(dim, kv_dim, bias = <span class="literal">False</span>)</span><br><span class="line">        <span class="variable language_">self</span>.proj_k = nn.Parameter(init_(torch.zeros(seq_len, k)))</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.share_kv = share_kv</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> share_kv:</span><br><span class="line">            <span class="variable language_">self</span>.to_v = nn.Linear(dim, kv_dim, bias = <span class="literal">False</span>)</span><br><span class="line">            <span class="variable language_">self</span>.proj_v = nn.Parameter(init_(torch.zeros(seq_len, k)))</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.dropout = nn.Dropout(dropout)</span><br><span class="line">        <span class="variable language_">self</span>.to_out = nn.Linear(dim_head * heads, dim)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, context = <span class="literal">None</span>, **kwargs</span>):</span><br><span class="line">        b, n, d, d_h, h, k = *x.shape, <span class="variable language_">self</span>.dim_head, <span class="variable language_">self</span>.heads, <span class="variable language_">self</span>.k</span><br><span class="line"></span><br><span class="line">        kv_len = n <span class="keyword">if</span> context <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> context.shape[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">assert</span> kv_len &lt;= <span class="variable language_">self</span>.seq_len, <span class="string">f&#x27;the sequence length of the key / values must be <span class="subst">&#123;self.seq_len&#125;</span> - <span class="subst">&#123;kv_len&#125;</span> given&#x27;</span></span><br><span class="line"></span><br><span class="line">        queries = <span class="variable language_">self</span>.to_q(x)</span><br><span class="line"></span><br><span class="line">        proj_seq_len = <span class="keyword">lambda</span> args: torch.einsum(<span class="string">&#x27;bnd,nk-&gt;bkd&#x27;</span>, *args)</span><br><span class="line"></span><br><span class="line">        kv_input = x <span class="keyword">if</span> context <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> context</span><br><span class="line"></span><br><span class="line">        keys = <span class="variable language_">self</span>.to_k(kv_input)</span><br><span class="line">        values = <span class="variable language_">self</span>.to_v(kv_input) <span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.share_kv <span class="keyword">else</span> keys</span><br><span class="line"></span><br><span class="line">        kv_projs = (<span class="variable language_">self</span>.proj_k, <span class="variable language_">self</span>.proj_v <span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.share_kv <span class="keyword">else</span> <span class="variable language_">self</span>.proj_k)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># allow for variable sequence lengths (less than maximum sequence length) by slicing projections</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> kv_len &lt; <span class="variable language_">self</span>.seq_len:</span><br><span class="line">            kv_projs = <span class="built_in">map</span>(<span class="keyword">lambda</span> t: t[:kv_len], kv_projs)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># project keys and values along the sequence length dimension to k</span></span><br><span class="line">        <span class="comment"># 对 key/value 做低秩投影</span></span><br><span class="line">        keys, values = <span class="built_in">map</span>(proj_seq_len, <span class="built_in">zip</span>((keys, values), kv_projs))<span class="comment">#map(功能，输入) zip()-&gt;（k，proj_k）（v,proj_v）</span></span><br><span class="line">        <span class="comment">#[b,k,d][b,k,d]</span></span><br><span class="line">        <span class="comment"># merge head into batch for queries and key / values</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># queries → reshape + transpose → [b, h, n, d_h]</span></span><br><span class="line">        <span class="comment"># keys/values → reshape → [b, h, k, d_h]</span></span><br><span class="line">        queries = queries.reshape(b, n, h, -<span class="number">1</span>).transpose(<span class="number">1</span>, <span class="number">2</span>)<span class="comment">#[b,n,d]-&gt;[b,n,h,h_d]-&gt;[b,h,n,h_d]</span></span><br><span class="line"></span><br><span class="line">        merge_key_values = <span class="keyword">lambda</span> t: t.reshape(b, k, -<span class="number">1</span>, d_h).transpose(<span class="number">1</span>, <span class="number">2</span>).expand(-<span class="number">1</span>, h, -<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">        keys, values = <span class="built_in">map</span>(merge_key_values, (keys, values)) <span class="comment">#map(功能，输入)[b,k,d]-&gt;[b,k,h,h_d]-&gt;[b,h,k,h_d]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># attention</span></span><br><span class="line"></span><br><span class="line">        dots = torch.einsum(<span class="string">&#x27;bhnd,bhkd-&gt;bhnk&#x27;</span>, queries, keys) * (d_h ** -<span class="number">0.5</span>) <span class="comment">#复杂度是nkd，flops=每个位置是一个向量点乘，每个位置需要 d_h 次乘加，一共b*n*h个位置，所以是2dhnkd</span></span><br><span class="line">        attn = dots.softmax(dim=-<span class="number">1</span>)</span><br><span class="line">        attn = <span class="variable language_">self</span>.dropout(attn)</span><br><span class="line">        out = torch.einsum(<span class="string">&#x27;bhnk,bhkd-&gt;bhnd&#x27;</span>, attn, values)<span class="comment">#复杂度是ndk，flops是b*h*n*d个位置，每个位置k次乘加，所以是2dhnkd</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># split heads</span></span><br><span class="line">        out = out.transpose(<span class="number">1</span>, <span class="number">2</span>).reshape(b, n, -<span class="number">1</span>)<span class="comment">#bhnd_n-&gt;bnhd_n-&gt;bnd</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.to_out(out)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>ffn结构（feedforward）<ul>
<li><p>两层 Linear + 激活 + Dropout</p>
</li>
<li><p>引入门控机制GLU： <code>act(x) * v  也就是  GELU(x)*v</code></p>
</li>
<li><p>gelu的原理：<br>$<br>\text{GELU}(x) &#x3D; x \cdot \Phi(x)<br>$<br>标准正态分布的累积分布函数的近似实现：<br>$\text{GELU}(x) \approx 0.5 \cdot x \cdot \left(1 + \tanh\left( \sqrt{\frac{2}{\pi}} \cdot (x + 0.044715 x^3) \right) \right)$<br>实现了 高斯概率加权的 x（相当于柔和过渡）</p>
</li>
<li><p>数据流如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##正常版本数据流</span></span><br><span class="line">x → Linear(dim, dim*<span class="number">4</span>) [B, L, D][B, L, D*<span class="number">4</span>] 扩大特征维度</span><br><span class="line">    → GELU / ReLU / SiLU [B, L, D*<span class="number">4</span>][B, L, D*<span class="number">4</span>] 非线性变换</span><br><span class="line">    → Dropout [B, L, D*<span class="number">4</span>][B, L, D*<span class="number">4</span>] 正则化</span><br><span class="line">    → Linear(dim*<span class="number">4</span>, dim) [B, L, D*<span class="number">4</span>][B, L, D] 映射回原始维度</span><br><span class="line">    → Residual + LayerNorm</span><br><span class="line"><span class="comment">#GLU版本数据流</span></span><br><span class="line">x → Linear(dim, dim*<span class="number">8</span>)  → chunk 成 x1, x2</span><br><span class="line">    x1 → 激活(x1)</span><br><span class="line">    out = x1 * x2 <span class="comment">#GLU</span></span><br><span class="line">    → Dropout → Linear(dim*<span class="number">4</span>, dim)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GELU_</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.5</span> * x * (<span class="number">1</span> + torch.tanh(math.sqrt(<span class="number">2</span> / math.pi) * (x + <span class="number">0.044715</span> * torch.<span class="built_in">pow</span>(x, <span class="number">3</span>))))</span><br><span class="line"></span><br><span class="line">GELU = nn.GELU <span class="keyword">if</span> <span class="built_in">hasattr</span>(nn, <span class="string">&#x27;GELU&#x27;</span>) <span class="keyword">else</span> GELU_</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FeedForward</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, mult = <span class="number">4</span>, dropout = <span class="number">0.</span>, activation = <span class="literal">None</span>, glu = <span class="literal">False</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        activation = default(activation, GELU)</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.glu = glu</span><br><span class="line">        <span class="variable language_">self</span>.w1 = nn.Linear(dim, dim * mult * (<span class="number">2</span> <span class="keyword">if</span> glu <span class="keyword">else</span> <span class="number">1</span>))</span><br><span class="line">        <span class="variable language_">self</span>.act = activation()</span><br><span class="line">        <span class="variable language_">self</span>.dropout = nn.Dropout(dropout)</span><br><span class="line">        <span class="variable language_">self</span>.w2 = nn.Linear(dim * mult, dim)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, **kwargs</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.glu:</span><br><span class="line">            x = <span class="variable language_">self</span>.w1(x)</span><br><span class="line">            x = <span class="variable language_">self</span>.act(x)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            x, v = <span class="variable language_">self</span>.w1(x).chunk(<span class="number">2</span>, dim=-<span class="number">1</span>)</span><br><span class="line">            x = <span class="variable language_">self</span>.act(x) * v</span><br><span class="line"></span><br><span class="line">        x = <span class="variable language_">self</span>.dropout(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.w2(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<h2 id="2-4-分类输出"><a href="#2-4-分类输出" class="headerlink" title="2.4 分类输出"></a>2.4 分类输出</h2><ul>
<li>forward部分如下：  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通常 [CLS] token 最后用于做分类任务的输出 head（类似 BERT）。</span></span><br><span class="line">x = x.mean(dim = <span class="number">1</span>) <span class="keyword">if</span> <span class="variable language_">self</span>.pool == <span class="string">&#x27;mean&#x27;</span> <span class="keyword">else</span> x[:, <span class="number">0</span>] <span class="comment">#对所有 token（包括 patch 和 CLS）取平均；</span></span><br><span class="line"><span class="comment"># 否则取 [CLS] token，即 x[:, 0]；</span></span><br><span class="line"></span><br><span class="line">x = <span class="variable language_">self</span>.to_latent(x)</span><br><span class="line">out = <span class="variable language_">self</span>.mlp_head(x)</span><br><span class="line"><span class="keyword">return</span> out</span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="3-onnx导出"><a href="#3-onnx导出" class="headerlink" title="3.onnx导出"></a>3.onnx导出</h1><ul>
<li>onnx导出只需要在example加载原来保存的模型，然后导出。  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ✅ 6. 导出 ONNX 模型</span></span><br><span class="line">model.load_state_dict(torch.load(<span class="string">&quot;model/best_model_vit.pth&quot;</span>, map_location=<span class="string">&quot;cpu&quot;</span>))  <span class="comment"># 替换为你的路径</span></span><br><span class="line">dummy_input = torch.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>).to(device)</span><br><span class="line">model.to(device).<span class="built_in">eval</span>()</span><br><span class="line">torch.onnx.export(</span><br><span class="line">    model.module <span class="keyword">if</span> <span class="built_in">isinstance</span>(model, nn.DataParallel) <span class="keyword">else</span> model,</span><br><span class="line">    dummy_input,</span><br><span class="line">    <span class="string">&quot;model/final_model_vit.onnx&quot;</span>,</span><br><span class="line">    input_names=[<span class="string">&quot;input&quot;</span>],</span><br><span class="line">    output_names=[<span class="string">&quot;output&quot;</span>],</span><br><span class="line">    opset_version=<span class="number">16</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<ul>
<li>可以用netron查看模型结构。<br><img src="/./jpg/onnx-vit.jpg" alt="vit-onnx"></li>
</ul>
</li>
</ul>
<h1 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h1><ul>
<li>tensorrt编译测速</li>
<li>profiling分析</li>
<li>自定义layernorm</li>
<li>量化精度分析</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/07/27/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/vit%E6%BA%90%E7%A0%81%E8%AF%A6%E8%A7%A3/" data-id="cmdpbmn2n000g5qx968vdaz61" data-title="vit源码详解(linformer)" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Transformer/" rel="tag">Transformer</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/linformer/" rel="tag">linformer</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/vit/" rel="tag">vit</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/vit-pytorch/" rel="tag">vit-pytorch</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2025/07/27/markdown/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          markdown小技巧
        
      </div>
    </a>
  
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/markdown/">markdown</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%91%A8%E8%AE%A1%E5%88%92/">周计划</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/">基础知识</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F/">推理加速</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/FLOPS/" rel="tag">FLOPS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Transformer/" rel="tag">Transformer</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/attention/" rel="tag">attention</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/conv/" rel="tag">conv</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linformer/" rel="tag">linformer</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/profiling/" rel="tag">profiling</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/vit/" rel="tag">vit</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/vit-pytorch/" rel="tag">vit-pytorch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/week1/" rel="tag">week1</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%B0%8F%E6%8A%80%E5%B7%A7/" rel="tag">小技巧</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8/" rel="tag">显存占用</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%AE%97%E6%B3%95%E5%A4%8D%E6%9D%82%E5%BA%A6/" rel="tag">算法复杂度</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%BF%90%E7%AE%97%E9%87%8F/" rel="tag">运算量</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/FLOPS/" style="font-size: 10px;">FLOPS</a> <a href="/tags/Transformer/" style="font-size: 10px;">Transformer</a> <a href="/tags/attention/" style="font-size: 20px;">attention</a> <a href="/tags/conv/" style="font-size: 10px;">conv</a> <a href="/tags/linformer/" style="font-size: 10px;">linformer</a> <a href="/tags/profiling/" style="font-size: 10px;">profiling</a> <a href="/tags/vit/" style="font-size: 20px;">vit</a> <a href="/tags/vit-pytorch/" style="font-size: 20px;">vit-pytorch</a> <a href="/tags/week1/" style="font-size: 10px;">week1</a> <a href="/tags/%E5%B0%8F%E6%8A%80%E5%B7%A7/" style="font-size: 10px;">小技巧</a> <a href="/tags/%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8/" style="font-size: 10px;">显存占用</a> <a href="/tags/%E7%AE%97%E6%B3%95%E5%A4%8D%E6%9D%82%E5%BA%A6/" style="font-size: 10px;">算法复杂度</a> <a href="/tags/%E8%BF%90%E7%AE%97%E9%87%8F/" style="font-size: 10px;">运算量</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/07/">July 2025</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2025/07/28/%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F/vit-profiling/">vit-torch-profiling</a>
          </li>
        
          <li>
            <a href="/2025/07/28/%E5%91%A8%E8%AE%A1%E5%88%92/Week5/">Week5</a>
          </li>
        
          <li>
            <a href="/2025/07/28/%E5%91%A8%E8%AE%A1%E5%88%92/Week4/">Week4</a>
          </li>
        
          <li>
            <a href="/2025/07/28/%E5%91%A8%E8%AE%A1%E5%88%92/Week3/">Week3</a>
          </li>
        
          <li>
            <a href="/2025/07/28/%E5%91%A8%E8%AE%A1%E5%88%92/Week2/">Week2</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2025 sunhanyu<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>