<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Sunhanyu-Learning</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="Sunhanyu-Learning">
<meta property="og:url" content="http://example.com/page/2/index.html">
<meta property="og:site_name" content="Sunhanyu-Learning">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="sunhanyu">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Sunhanyu-Learning" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/fork-awesome@1.2.0/css/fork-awesome.min.css">

<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Sunhanyu-Learning</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-å‘¨è®¡åˆ’/Week2" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/07/28/%E5%91%A8%E8%AE%A1%E5%88%92/Week2/" class="article-date">
  <time class="dt-published" datetime="2025-07-28T05:16:29.000Z" itemprop="datePublished">2025-07-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2025/07/28/%E5%91%A8%E8%AE%A1%E5%88%92/Week2/">Week2</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/07/28/%E5%91%A8%E8%AE%A1%E5%88%92/Week2/" data-id="cmdwxao6100085ox99w7c6dar" data-title="Week2" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-å‘¨è®¡åˆ’/Week1" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/07/28/%E5%91%A8%E8%AE%A1%E5%88%92/Week1/" class="article-date">
  <time class="dt-published" datetime="2025-07-28T05:16:04.000Z" itemprop="datePublished">2025-07-28</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E5%91%A8%E8%AE%A1%E5%88%92/">å‘¨è®¡åˆ’</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2025/07/28/%E5%91%A8%E8%AE%A1%E5%88%92/Week1/">Week1</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h3 id="day1-20250728"><a href="#day1-20250728" class="headerlink" title="day1-20250728"></a>day1-20250728</h3><ul>
<li><input checked="" disabled="" type="checkbox"> vit-attention onnxå¯¼å‡º</li>
<li><input checked="" disabled="" type="checkbox"> ç”Ÿæˆ PyTorch Profiler è„šæœ¬ï¼›å¯¼å‡ºå¯è§†åŒ–å›¾è¡¨ï¼ˆå¦‚ chrome traceã€timeline å›¾ï¼‰ï¼›</li>
<li><input checked="" disabled="" type="checkbox"> ä¿®æ”¹ä¸åŒçš„attentionç‰ˆæœ¬æŸ¥çœ‹profilingçš„å˜åŒ–ã€‚</li>
</ul>
<h3 id="day2-20250729"><a href="#day2-20250729" class="headerlink" title="day2-20250729"></a>day2-20250729</h3><ul>
<li><input checked="" disabled="" type="checkbox"> è®¡ç®—æ¨¡å‹çš„flopsï¼Œå‚æ•°é‡å’Œæ˜¾å­˜å ç”¨</li>
</ul>
<h3 id="day3-20250730"><a href="#day3-20250730" class="headerlink" title="day3-20250730"></a>day3-20250730</h3><ul>
<li><input checked="" disabled="" type="checkbox"> ç†Ÿæ‚‰å·¥ç¨‹çš„pipline-ç¬”è®°åœ¨notion</li>
<li><input checked="" disabled="" type="checkbox"> kv cacheçš„æºç å¦‚ä½•å®ç°çš„ï¼Ÿqkvç›¸ä¹˜å¦‚ä½•åšçš„ï¼Ÿ</li>
</ul>
<h3 id="day4-20250731"><a href="#day4-20250731" class="headerlink" title="day4-20250731"></a>day4-20250731</h3><ul>
<li><input disabled="" type="checkbox"> å­¦ä¹ åå¤„ç†çš„nmsï¼Œiouè®¡ç®—ç­‰ç®—æ³•çš„c++å®ç°ã€‚</li>
<li><input disabled="" type="checkbox"> å­¦ä¹ å‰å¤„ç†åŠ é€Ÿç®—å­å¦‚ä½•å®ç°(cudaå®ç°)</li>
<li><input disabled="" type="checkbox"> åœ¨vitæ¨¡å‹åŸºç¡€ä¸Šæ„å»ºä¸€ä¸ª attention å­å›¾æ‹†è§£ Demoï¼ˆTensorRTï¼‰ï¼›</li>
<li><input disabled="" type="checkbox"> å…ˆè½¬æ¢vitä¸ºtrtæ¨¡å‹ï¼Œçœ‹çœ‹æœ‰å“ªäº›ç®—å­è¢«fallback cpuï¼Œåœ¨è¿›è¡Œå®ç°ã€‚å…¶ä¸­è¿˜è¦çœ‹çœ‹trtå¦‚ä½•è½¬engineï¼Œé™¤äº†å‘½ä»¤è¡Œã€‚pythonå¦‚ä½•è½¬æ¢å‘¢ï¼Ÿ</li>
<li><input disabled="" type="checkbox"> å¯¹æ¯”tensort int8 fp16 fp32çš„å®é™…flopsï¼Œä»¥åŠprofilingã€‚</li>
<li><input disabled="" type="checkbox"> ç”¨ trtexec åˆ†ææ¨¡å‹æ¯å±‚è€—æ—¶ï¼ŒNsight Compute åˆ†æ LayerNorm çš„ç“¶é¢ˆã€‚è‡ªå®šä¹‰tensorrtçš„layernormä¹‹åï¼Œæµ‹è¯•profilingæœ‰æ²¡æœ‰å˜åŒ–ã€‚</li>
<li><input disabled="" type="checkbox"> ç®—æ³•é¢˜åˆ·é¢˜ï¼ˆ704. äºŒåˆ†æŸ¥æ‰¾ 27.ç§»é™¤å…ƒç´ ï¼‰</li>
</ul>
<h3 id="åç»­è®¡åˆ’"><a href="#åç»­è®¡åˆ’" class="headerlink" title="åç»­è®¡åˆ’"></a>åç»­è®¡åˆ’</h3><ul>
<li><input disabled="" type="checkbox"> tensorrtéƒ¨ç½²vitå’Œqwenæ¨¡å‹</li>
<li><input disabled="" type="checkbox"> æµ‹è¯•ä¸Šè¿°é‡åŒ–ç²¾åº¦å¹¶ä¼˜åŒ–é‡åŒ–ç²¾åº¦</li>
<li><input disabled="" type="checkbox"> èŠ¯ç‰‡åº•å±‚å¦‚ä½•å®ç°çš„çŸ©é˜µä¹˜å’Œå·ç§¯ï¼Œæˆ‘è¯¥å¦‚ä½•åŠ é€Ÿï¼Ÿ</li>
<li><input disabled="" type="checkbox"> tensorrt plugin å®ç° <a target="_blank" rel="noopener" href="https://github.com/TrojanXu/onnxparser-trt-plugin-sample">https://github.com/TrojanXu/onnxparser-trt-plugin-sample</a></li>
<li><input disabled="" type="checkbox"> é™¤äº†ä¼˜åŒ–æ¨¡å‹ç»“æ„ï¼Œè¿˜èƒ½ä»cacheå’Œflash attentionçš„æ–¹å‘ä¼˜åŒ–æ¨¡å‹çš„æ¨ç†é€Ÿåº¦ã€‚(ä½¿ç”¨hungging faceå’Œvllmæµ‹è¯•)</li>
<li><input disabled="" type="checkbox"> c++å…«è‚¡æ–‡</li>
<li><input disabled="" type="checkbox"> æ¨¡å‹éƒ¨ç½²å…«è‚¡æ–‡å­¦ä¹ </li>
<li><input disabled="" type="checkbox"> æ•´ç†å­¦ä¹ çŸ¥è¯†ç‚¹</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/07/28/%E5%91%A8%E8%AE%A1%E5%88%92/Week1/" data-id="cmdwxao6000075ox983roa88h" data-title="Week1" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/week1/" rel="tag">week1</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-åŸºç¡€çŸ¥è¯†/flopså’Œè®¡ç®—å¤æ‚åº¦" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/07/28/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/flops%E5%92%8C%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E5%BA%A6/" class="article-date">
  <time class="dt-published" datetime="2025-07-27T16:00:00.000Z" itemprop="datePublished">2025-07-28</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/">åŸºç¡€çŸ¥è¯†</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2025/07/28/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/flops%E5%92%8C%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E5%BA%A6/">vitæºç è¯¦è§£(linformer)</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="1-ä»€ä¹ˆæ˜¯FLOPsï¼Ÿ"><a href="#1-ä»€ä¹ˆæ˜¯FLOPsï¼Ÿ" class="headerlink" title="1.ä»€ä¹ˆæ˜¯FLOPsï¼Ÿ"></a>1.ä»€ä¹ˆæ˜¯FLOPsï¼Ÿ</h1><p>FLOPsï¼ˆfloating point operationsï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦ä¸­çš„ä¸€ä¸ªæ¦‚å¿µï¼Œè¡¨ç¤ºä¸€ä¸ªè®¡ç®—è®¾å¤‡ï¼ˆå¦‚CPUæˆ–GPUï¼‰æ‰§è¡Œå•ä¸ªè¿ç®—æ‰€éœ€çš„æµ®ç‚¹è¿ç®—æ¬¡æ•°ã€‚</p>
<p>å¦‚attentionä¸­çš„Q.shape&#x3D;[B, N, C]ï¼ŒK.shape&#x3D;[B, N, C]ï¼ŒV.shape&#x3D;[B, N, C]ï¼Œé‚£ä¹ˆQ<em>K.T.shape&#x3D;[B, N, N]ï¼Œé‚£ä¹ˆQ</em>K.Tçš„FLOPsä¸ºB<em>N</em>N<em>C</em>2,å…·ä½“è§£é‡Šä¸ºæœ€ç»ˆè®¡ç®—åçš„shapeä¸º[B, N, N]ï¼Œé‚£ä¹ˆN<em>Nä¸ªä½ç½®è¿›è¡Œ2</em>Cçš„ä¹˜åŠ è¿ç®—ï¼ŒBæ¬¡ã€‚</p>
<h1 id="2-ä»€ä¹ˆæ˜¯ç®—æ³•å¤æ‚åº¦ï¼Ÿ"><a href="#2-ä»€ä¹ˆæ˜¯ç®—æ³•å¤æ‚åº¦ï¼Ÿ" class="headerlink" title="2.ä»€ä¹ˆæ˜¯ç®—æ³•å¤æ‚åº¦ï¼Ÿ"></a>2.ä»€ä¹ˆæ˜¯ç®—æ³•å¤æ‚åº¦ï¼Ÿ</h1><p>ç®—æ³•å¤æ‚åº¦ï¼ˆAlgorithm Complexityï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦ä¸­çš„ä¸€ä¸ªæ¦‚å¿µï¼Œç”¨äºæè¿°ä¸€ä¸ªç®—æ³•çš„è¿è¡Œæ•ˆç‡ã€‚<br>ç®—æ³•å¤æ‚åº¦é€šå¸¸ç”¨Big O notationæ¥è¡¨ç¤ºï¼Œæ¯”å¦‚O(n^2)è¡¨ç¤ºä¸€ä¸ªç®—æ³•çš„æ—¶é—´å¤æ‚åº¦ä¸ºnçš„å¹³æ–¹ã€‚<br>å¦‚attentionä¸­çš„Q.shape&#x3D;[B, N, C]ï¼ŒK.shape&#x3D;[B, N, C]ï¼ŒV.shape&#x3D;[B, N, C]ï¼Œé‚£ä¹ˆQ*K.Tçš„ç®—æ³•å¤æ‚åº¦ä¸ºO($N^2C$)</p>
<p>é‚£ä¹ˆï¼Œå¯¹äºé•¿åºåˆ—æ¥è¯´Nå°±æ˜¯ç“¶é¢ˆï¼Œå¯¹äºçŸ­åºåˆ—æ¥è¯´Cä¹Ÿå°±æ˜¯éšè—å±‚çš„ç»´åº¦å°±æ˜¯ç“¶é¢ˆã€‚</p>
<h1 id="3-floaté‡åŒ–æˆintå‡å°‘çš„æ˜¯ä»€ä¹ˆï¼Ÿ"><a href="#3-floaté‡åŒ–æˆintå‡å°‘çš„æ˜¯ä»€ä¹ˆï¼Ÿ" class="headerlink" title="3.floaté‡åŒ–æˆintå‡å°‘çš„æ˜¯ä»€ä¹ˆï¼Ÿ"></a>3.floaté‡åŒ–æˆintå‡å°‘çš„æ˜¯ä»€ä¹ˆï¼Ÿ</h1><ul>
<li>å‡å°‘çš„å†…å­˜å ç”¨å’Œå†…å­˜å¸¦å®½å‹åŠ›</li>
<li>float32 4ä¸ªå­—èŠ‚ int4 0.5ä¸ªå­—èŠ‚ èŠ‚çœæ˜¾å­˜87.5% </li>
<li>int4çš„macè®¡ç®—æ¬¡æ•°ä¸ä¼šå˜åŒ–ï¼Œä½†æ˜¯å•æ¬¡çš„macè®¡ç®—çš„æ¶ˆè€—æ›´ä½ã€‚</li>
</ul>
<h1 id="4-å‚æ•°é‡ï¼Œæ˜¾å­˜å ç”¨å’Œè¿ç®—é‡çš„åŒºåˆ«"><a href="#4-å‚æ•°é‡ï¼Œæ˜¾å­˜å ç”¨å’Œè¿ç®—é‡çš„åŒºåˆ«" class="headerlink" title="4.å‚æ•°é‡ï¼Œæ˜¾å­˜å ç”¨å’Œè¿ç®—é‡çš„åŒºåˆ«"></a>4.å‚æ•°é‡ï¼Œæ˜¾å­˜å ç”¨å’Œè¿ç®—é‡çš„åŒºåˆ«</h1><ul>
<li>å‚æ•°é‡ï¼šå‚æ•°æ•°é‡ï¼Œå³æ¨¡å‹ä¸­å¯è®­ç»ƒçš„å‚æ•°æ•°é‡ã€‚ä»¥æŸå±‚çš„ Query æƒé‡çŸ©é˜µ W_q ä¸ºä¾‹ï¼Œè¾“å…¥ç»´åº¦æ˜¯ d&#x3D;4096ï¼Œè¾“å‡ºä¹Ÿæ˜¯ d_k&#x3D;4096ï¼Œé‚£ä¹ˆå‚æ•°é‡ä¸º 4096 * 4096 &#x3D; 16,777,216 çº¦ç­‰äº 1.68Mã€‚</li>
<li>æ˜¾å­˜å ç”¨ï¼šæ¨¡å‹è¿è¡Œæ—¶åœ¨æ˜¾å­˜çš„å ç”¨é‡ã€‚é™¤äº†æ¨¡å‹æ¯å±‚çš„æƒé‡çŸ©é˜µå‚æ•°éœ€è¦æ˜¾å­˜å ç”¨å¤–ï¼Œè¿˜è¦è€ƒè™‘æ¯å±‚attentionçš„ä¸­é—´è¾“å‡ºï¼ˆactivationsï¼‰ï¼Œè¿˜æœ‰attentionä¸­ä¿å­˜çš„ Key&#x2F;Value ç”¨äºåŠ é€Ÿè§£ç ã€‚<ul>
<li>æƒé‡å‚æ•°å ç”¨ï¼šä»¥fp16ä¸ºä¾‹å­ï¼Œ7Bæ¨¡å‹å‚æ•°å ç”¨ä¸ºï¼š7B âœ–ï¸ 2  &#x3D; 14B</li>
<li>KVå ç”¨ï¼šï¼ˆlayers * batch_size * seq_len * hidden_sizeï¼‰ * 2ï¼‰* 2B</li>
</ul>
</li>
<li>è¿ç®—é‡ï¼ˆFLOPsï¼‰ï¼šæ¨ç†ï¼ˆæˆ–è®­ç»ƒï¼‰æ‰€éœ€çš„æµ®ç‚¹è¿ç®—æ¬¡æ•°ï¼ˆFloating Point Operationsï¼‰ã€‚ä¸€åŠ ä¸€ä¹˜ç›¸å½“äº2FLOPsã€‚</li>
</ul>
<h1 id="5-convçš„flopsï¼Œå‚æ•°é‡å’Œæ˜¾å­˜å ç”¨"><a href="#5-convçš„flopsï¼Œå‚æ•°é‡å’Œæ˜¾å­˜å ç”¨" class="headerlink" title="5. convçš„flopsï¼Œå‚æ•°é‡å’Œæ˜¾å­˜å ç”¨"></a>5. convçš„flopsï¼Œå‚æ•°é‡å’Œæ˜¾å­˜å ç”¨</h1><ul>
<li>æ¯ä¸ªè¾“å‡ºä½ç½®åšä¸€æ¬¡å·ç§¯æ ¸çš„ dot productï¼Œæ¯ä¸ªå·ç§¯æ ¸çš„å‚æ•°ä¸ªæ•°ä¸º Cin Ã— Kh Ã— Kwï¼Œè¾“å‡ºå¤§å°æ˜¯ Hout Ã— Woutï¼Œä¸€å…±Cout ä¸ªå·ç§¯æ ¸ï¼Œé‚£ä¹ˆ</li>
<li>FLOPsè®¡ç®—é‡ä¸ºï¼š<code>FLOPs = 2 Ã— Cout Ã— Hout Ã— Wout Ã— Cin Ã— Kh Ã— Kw x Batch</code><br>  â€¢Cout: è¾“å‡ºé€šé“æ•°<br>  â€¢Hout, Wout: è¾“å‡ºç‰¹å¾å›¾çš„é«˜å’Œå®½<br>  â€¢Cin: è¾“å…¥é€šé“æ•°<br>  â€¢Kh, Kw: å·ç§¯æ ¸çš„é«˜å’Œå®½ï¼ˆKernel Height &#x2F; Widthï¼‰<br>  â€¢2: è¡¨ç¤ºä¸€æ¬¡ä¹˜æ³• + ä¸€æ¬¡åŠ æ³•ï¼ˆMAC æ“ä½œç®—ä¸¤æ¬¡ FLOPsï¼‰</li>
<li>å‚æ•°é‡ï¼šæ¯ä¸ªå·ç§¯æ ¸å¤§å°ä¸ºï¼šCin Ã— Kh Ã— Kwï¼Œå…± C_out ä¸ªå·ç§¯æ ¸ â†’ æ€»å‚æ•°é‡ä¸ºï¼š<code>Params_conv = C_out Ã— C_in Ã— K Ã— K</code></li>
<li>æ˜¾å­˜å ç”¨ï¼šè¿™é‡Œçš„æ˜¾å­˜å ç”¨ä¸»è¦è®¡ç®—çš„æ˜¯æ¿€æ´»å€¼çš„å ç”¨<code>Memory_conv â‰ˆ Batch Ã— C_out Ã— H_out Ã— W_out Ã— sizeof(float/int)</code><ul>
<li>å…¶ä¸­float32å 4å­—èŠ‚ï¼Œfloat16å 2ä¸ªå­—èŠ‚ï¼Œint8å 1å­—èŠ‚ï¼Œint4å 0.5ä¸ªå­—èŠ‚.</li>
</ul>
</li>
</ul>
<h1 id="6-attentionçš„flopsï¼Œå‚æ•°é‡å’Œæ˜¾å­˜å ç”¨"><a href="#6-attentionçš„flopsï¼Œå‚æ•°é‡å’Œæ˜¾å­˜å ç”¨" class="headerlink" title="6. attentionçš„flopsï¼Œå‚æ•°é‡å’Œæ˜¾å­˜å ç”¨"></a>6. attentionçš„flopsï¼Œå‚æ•°é‡å’Œæ˜¾å­˜å ç”¨</h1><ul>
<li>è¾“å…¥ç»´åº¦ï¼šB Ã— L Ã— Dï¼ˆbatch, seq_len, embedding_dimï¼‰</li>
<li>å‡è®¾ç”¨æ ‡å‡† QKV æ³¨æ„åŠ›æœºåˆ¶ï¼Œhead æ•°ä¸º Hï¼Œæ¯ä¸ª head ç»´åº¦ä¸º d &#x3D; D &#x2F; H</li>
<li>ä¸»è¦åŒ…å«å››ä¸ªçº¿æ€§å±‚ï¼šQKV+è¾“å‡ºæ˜ å°„ï¼Œä¸€ä¸ªlayernormå±‚å¯å­¦ä¹ å‚æ•°çš„å‚æ•°é‡ä¸º2Dï¼Œçº¿æ€§å±‚çš„biasçš„å‚æ•°é‡ä¸ºD-&gt;4D</li>
<li>å‚æ•°é‡ï¼š<code>Params_attn = 3 Ã— D Ã— D [+ D Ã— D]â‰ˆ 4 Ã— D Ã— D + 6D</code></li>
<li>FLOPSä¸»è¦æ¥æºå››ä¸ªçº¿æ€§å±‚çš„è®¡ç®—å’ŒQ<em>Kï¼ŒA</em>Vçš„è®¡ç®—</li>
<li>FLOPSï¼š<code>FLOPs_attn = 4 Ã— Batch x 2 x D Ã— D x L + Batch x 2 Ã— D Ã— L x L + Batch x 2 Ã— D Ã— L x L</code></li>
<li>æ˜¾å­˜å ç”¨ï¼š<ul>
<li>attentionçš„æ˜¾å­˜å ç”¨åŒ…æ‹¬QKVçš„è¾“å…¥xï¼Œå ç”¨æ˜¾å­˜å¤§å°ä¸º2BLDã€‚</li>
<li>QKè®¡ç®—çš„è¾“å…¥Qï¼ŒKï¼Œå ç”¨æ˜¾å­˜å¤§å°ä¸º4BLDï¼Œ</li>
<li>softmaxè®¡ç®—ä¿å­˜QKçš„ç»“æœ2BL^2a,å…¶ä¸­aæŒ‡çš„æ˜¯headçš„æ•°é‡ã€‚</li>
<li>softmaxåçš„dropoutéœ€è¦ä¸€ä¸ªQKç»´åº¦ç›¸åŒçš„çŸ©é˜µï¼Œå ç”¨æ˜¾å­˜å¤§å°ä¸ºBL^2aï¼Œå› ä¸ºmaskçŸ©é˜µçš„å ç”¨å­—èŠ‚æ•°ä¸º1 bytesã€‚</li>
<li>A*Vçš„è¾“å…¥Aï¼ŒVï¼Œå ç”¨æ˜¾å­˜å¤§å°ä¸º2BL^2a+2BLDã€‚</li>
<li>æœ€åè®¡ç®—è¾“å‡ºæ˜ å°„éœ€è¦ä¿å­˜è¾“å…¥ï¼Œå ç”¨æ˜¾å­˜å¤§å°ä¸º2BLDã€‚å†åŠ ä¸ŠdropoutçŸ©é˜µï¼Œå ç”¨æ˜¾å­˜å¤§å°ä¸ºBLDã€‚</li>
<li>æœ€ç»ˆä¸­é—´æ¿€æ´»å ç”¨çš„æ˜¾å­˜å¤§å°ä¸º11BLD+5BL^2aã€‚</li>
<li>è¿˜æœ‰ä¸€ä¸ªlayer normï¼Œè¾“å…¥çš„å ç”¨æ˜¾å­˜å¤§å°ä¸º2BLDã€‚</li>
</ul>
</li>
</ul>
<h1 id="7-MLPçš„flopsï¼Œå‚æ•°é‡å’Œæ˜¾å­˜å ç”¨"><a href="#7-MLPçš„flopsï¼Œå‚æ•°é‡å’Œæ˜¾å­˜å ç”¨" class="headerlink" title="7. MLPçš„flopsï¼Œå‚æ•°é‡å’Œæ˜¾å­˜å ç”¨"></a>7. MLPçš„flopsï¼Œå‚æ•°é‡å’Œæ˜¾å­˜å ç”¨</h1><ul>
<li>è¾“å…¥ç»´åº¦ï¼šB Ã— L Ã— Dï¼ˆbatch, seq_len, embedding_dimï¼‰</li>
<li>å‡è®¾ç”¨æ ‡å‡† MLP æ˜ å°„ï¼Œhidden_dim ä¸º 4*D</li>
<li>ä¸»è¦åŒ…æ‹¬ä¸¤ä¸ªçº¿æ€§å±‚ï¼šå‡ç»´+é™ç»´ï¼Œä¸€ä¸ªlayernormå±‚å¯å­¦ä¹ å‚æ•°çš„å‚æ•°é‡ä¸º2Dï¼Œçº¿æ€§å±‚çš„biasçš„å‚æ•°é‡ä¸ºD+4D</li>
<li>å‚æ•°é‡ï¼š<code>Params_mlp = 2 Ã— D Ã— hidden_dim â‰ˆ 8 Ã— D Ã— D +7D</code></li>
<li>FLOPsä¸»è¦æ¥æºä¸¤ä¸ªçº¿æ€§å±‚</li>
<li>FLOPSï¼š<code>FLOPS_mlp = 2 x Batch x 2 Ã— D Ã— hidden_dim x L </code></li>
<li>æ˜¾å­˜å ç”¨ï¼š<ul>
<li>ç¬¬ä¸€ä¸ªçº¿æ€§å±‚éœ€è¦ä¿å­˜å…¶è¾“å…¥ï¼Œå ç”¨æ˜¾å­˜å¤§å°ä¸º2BLD</li>
<li>æ¿€æ´»å‡½æ•°éœ€è¦ä¿å­˜è¾“å…¥ï¼Œå ç”¨æ˜¾å­˜å¤§å°ä¸º8BLD</li>
<li>ç¬¬2ä¸ªçº¿æ€§å±‚éœ€è¦ä¿å­˜å…¶è¾“å…¥ï¼Œå ç”¨æ˜¾å­˜å¤§å°ä¸º2BLD</li>
<li>dropoutéœ€è¦ä¿å­˜è¾“å…¥ï¼Œå ç”¨æ˜¾å­˜å¤§å°ä¸ºBLD</li>
<li>æœ€ç»ˆä¿å­˜çš„æ˜¾å­˜å¤§å°ä¸º19BLD.</li>
<li>è¿˜æœ‰ä¸€ä¸ªLayerNormå±‚ï¼Œéœ€è¦ä¿å­˜å…¶è¾“å…¥ï¼Œå ç”¨æ˜¾å­˜å¤§å°ä¸º2BLD</li>
</ul>
</li>
</ul>
<h1 id="8-lå±‚transformerçš„floopsï¼Œå‚æ•°é‡å’Œæ˜¾å­˜å ç”¨"><a href="#8-lå±‚transformerçš„floopsï¼Œå‚æ•°é‡å’Œæ˜¾å­˜å ç”¨" class="headerlink" title="8. lå±‚transformerçš„floopsï¼Œå‚æ•°é‡å’Œæ˜¾å­˜å ç”¨"></a>8. lå±‚transformerçš„floopsï¼Œå‚æ•°é‡å’Œæ˜¾å­˜å ç”¨</h1><ul>
<li>å‚æ•°é‡ï¼š<code>Params_transformer = Params_attn + Params_mlp â‰ˆ l x (4 Ã— D Ã— D + 8 Ã— D Ã— D) + 13D x l</code>ï¼Œæ€»è®¡çº¦ç­‰äº$12lD^2$<br>ä¾‹å¦‚ä¸åŒçš„llamaï¼Œéšè—å±‚çš„ç»´åº¦ä¸åŒï¼Œæ¨¡å‹çš„å‚æ•°é‡ä¹Ÿä¸åŒã€‚<br>ï½œå®é™…å‚æ•°é‡ ï½œéšè—ç»´åº¦h ï½œå±‚æ•°l	ï½œ12lh^2ï½œ<br>ï½œâ€”â€”â€”-ï½œâ€”â€”â€”ï½œâ€”â€”â€“ï½œâ€”â€”ï½œ<br>ï½œ	6.7B	ï½œ4096	ï½œ32	 ï½œ6,442,450,944ï½œ<br>ï½œ	13.0B	ï½œ5120	ï½œ40	 ï½œ12,582,912,000ï½œ<br>ï½œ	32.5B	ï½œ6656	ï½œ60	 ï½œ31,897,681,920ï½œ<br>ï½œ	65.2B	ï½œ8192	ï½œ80	 ï½œ64,424,509,440ï½œ</li>
<li>flops ï¼š$FLOPS_{transformer} &#x3D; FLOPS{attn} + FLOPS{mlp} â‰ˆ l(24BLD^2 + 4BL^2D) &#x3D; 24lBLD^2$</li>
<li>flopså’Œå‚æ•°é‡ä¹‹é—´çš„å…³ç³»è¿‘ä¼¼ä¸ºBLä¸ªtokenéœ€è¦è¿›è¡Œä¸€ä¸ªä¹˜æ³•ä¸€ä¸ªåŠ æ³•è¿ç®—&#x3D;2BLã€‚</li>
<li>æ˜¾å­˜å ç”¨ï¼š<ul>
<li>transformerå±‚éœ€è¦ä¿å­˜çš„ä¸­é—´æ¿€æ´»å ç”¨æ˜¾å­˜å¤§å°ä¸º $(34BLD+5BL^2a)*l$ã€‚</li>
<li>å¯¹æ¯”ä¸€ä¸ªllama 7bçš„æ¨¡å‹ï¼Œéšè—å±‚ç»´åº¦Dä¸º4096ï¼Œl&#x3D;32å±‚ï¼Œåºåˆ—é•¿åº¦Lä¸º2048ï¼Œa&#x3D;1ï¼Œé‚£ä¹ˆä»–çš„æ˜¾å­˜å ç”¨åœ¨ä¸åŒçš„batch sizeä¸‹å¯¹æ¯”ï¼š</li>
<li>7bæ¨¡å‹çš„æ˜¾å­˜å ç”¨ä¸º14Gã€‚</li>
<li>$batchsize &#x3D; 1 -&gt; (34<em>1</em>2048<em>4096+5</em>1<em>2048</em>2048*1)*32&#x3D;306184192Ã—32&#x3D;9797894144&#x3D;9.7G$</li>
<li>$batchsize &#x3D; 3 -&gt; (34<em>3</em>2048<em>4096+5</em>3<em>2048</em>2048*1)*32&#x3D;29393682432&#x3D;29.4G$</li>
<li>$batchsize &#x3D; 32 -&gt; (34<em>32</em>2048<em>4096+5</em>32<em>2048</em>2048*1)*32&#x3D;313532612608&#x3D;313.5G$</li>
<li>å¦‚ä¸Šè¿°è®¡ç®—æ‰€ç¤ºï¼Œæ¨¡å‹çš„æ˜¾å­˜å ç”¨éšbatch sizeçš„å¢å¤§è€Œå¢å¤§ã€‚ä¸€æ¬¡éœ€è¦é€šè¿‡æ¿€æ´»é‡è®¡ç®—ã€flash attentionç­‰æ–¹å¼ä¼˜åŒ–æ˜¾å­˜å ç”¨ã€‚</li>
</ul>
</li>
</ul>
<h1 id="9-KV-cacheçš„æ˜¾å­˜å ç”¨åˆ†æ"><a href="#9-KV-cacheçš„æ˜¾å­˜å ç”¨åˆ†æ" class="headerlink" title="9. KV cacheçš„æ˜¾å­˜å ç”¨åˆ†æ"></a>9. KV cacheçš„æ˜¾å­˜å ç”¨åˆ†æ</h1><ul>
<li>å‡è®¾è¾“å…¥åºåˆ—çš„é•¿åº¦ä¸ºn ï¼Œè¾“å‡ºåºåˆ—çš„é•¿åº¦ä¸ºnï¼Œä»¥float16æ¥ä¿å­˜KV cacheï¼Œé‚£ä¹ˆKV cacheçš„å³°å€¼æ˜¾å­˜å ç”¨å¤§å°ä¸º2<em>2</em>(s+n)<em>B</em>Dã€‚è¿™é‡Œç¬¬ä¸€ä¸ª2è¡¨ç¤ºK&#x2F;V cacheï¼Œç¬¬äºŒä¸ª2è¡¨ç¤ºfloat16å 2ä¸ªbytesã€‚</li>
<li>ä¼˜åŒ–kv cacheçš„æ˜¾å­˜å ç”¨æ–¹æ³•æœ‰ï¼šé‡åŒ–ã€å…±äº«kvç­‰ã€‚</li>
</ul>
<h1 id="å‚è€ƒ"><a href="#å‚è€ƒ" class="headerlink" title="å‚è€ƒ"></a>å‚è€ƒ</h1><p>[1] <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/624740065?s_r=0">åˆ†ætransfomerçš„å‚æ•°é‡å’Œè®¡ç®—é‡ä»¥åŠä¸­é—´æ¿€æ´»ã€kv cache</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/07/28/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/flops%E5%92%8C%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E5%BA%A6/" data-id="cmdwxao64000g5ox9gl8pa90s" data-title="vitæºç è¯¦è§£(linformer)" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/FLOPS/" rel="tag">FLOPS</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/attention/" rel="tag">attention</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/conv/" rel="tag">conv</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8/" rel="tag">æ˜¾å­˜å ç”¨</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%AE%97%E6%B3%95%E5%A4%8D%E6%9D%82%E5%BA%A6/" rel="tag">ç®—æ³•å¤æ‚åº¦</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%BF%90%E7%AE%97%E9%87%8F/" rel="tag">è¿ç®—é‡</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-hello-world" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/07/27/hello-world/" class="article-date">
  <time class="dt-published" datetime="2025-07-27T08:45:42.879Z" itemprop="datePublished">2025-07-27</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2025/07/27/hello-world/">Hello World</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/07/27/hello-world/" data-id="cmdwxao5u00015ox9eif31ihu" data-title="Hello World" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-markdown" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/07/27/markdown/" class="article-date">
  <time class="dt-published" datetime="2025-07-26T16:00:00.000Z" itemprop="datePublished">2025-07-27</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/markdown/">markdown</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2025/07/27/markdown/">markdownå°æŠ€å·§</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>ğŸ§  ç¨‹åºå‘˜å¸¸ç”¨çš„ Markdown å°æŠ€å·§</p>
<p>âœ… 1. é«˜äº®ä»£ç å—</p>
<p>ä½¿ç”¨ä¸‰åå¼•å· &#96;&#96;&#96; æ ‡è®°ä»£ç åŒºåŸŸï¼Œå¹¶æ³¨æ˜è¯­è¨€ï¼Œè‡ªåŠ¨è¯­æ³•é«˜äº®ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">```python</span><br><span class="line">def hello():</span><br><span class="line">    print(&quot;Hello, Markdown!&quot;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">âœ… 2. ä»»åŠ¡æ¸…å• / Todo åˆ—è¡¨</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><input checked="" disabled="" type="checkbox"> å®Œæˆæ¨¡å‹è®­ç»ƒ</li>
<li><input disabled="" type="checkbox"> å¯¼å‡ºä¸º ONNX</li>
<li><input disabled="" type="checkbox"> å†™å¥½ README</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">âœ… 3. è¡¨æ ¼å¿«é€Ÿæ’åˆ—å¯¹æ¯”ä¿¡æ¯</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>æ¨¡å‹å</th>
<th>ç²¾åº¦ Top1</th>
<th>æ¨ç†æ—¶é—´</th>
</tr>
</thead>
<tbody><tr>
<td>ResNet50</td>
<td>76.5%</td>
<td>12ms</td>
</tr>
<tr>
<td>MobileNetV2</td>
<td>71.8%</td>
<td>5ms</td>
</tr>
</tbody></table>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">âœ… 4. è‡ªåŠ¨ç¼–å· / åµŒå¥—åˆ—è¡¨</span><br></pre></td></tr></table></figure>
<ol>
<li>æ¨¡å‹å®šä¹‰<ul>
<li>ä½¿ç”¨ torch.nn</li>
<li>æ”¯æŒ dropout</li>
</ul>
</li>
<li>å¯¼å‡ºæµç¨‹<ul>
<li>ONNX export</li>
<li>éªŒè¯è¾“å‡ºå·®å¼‚</li>
</ul>
</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">âœ… 5. æ’å…¥å›¾ç‰‡ï¼ˆæ”¯æŒæœ¬åœ°/ç½‘ç»œï¼‰</span><br></pre></td></tr></table></figure>
<p><img src="/./vit_architecture.png" alt="ViTç»“æ„å›¾"></p>
<p>æˆ–ï¼š</p>
<p><img src="https://example.com/model.png" alt="æ¨¡å‹ç»“æ„å›¾"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">âœ… 6. æŠ˜å å†…å®¹ï¼ˆGitHub ä¸æ”¯æŒï¼ŒTypora æ”¯æŒï¼‰</span><br></pre></td></tr></table></figure>
<details>
  <summary>ç‚¹å‡»å±•å¼€æŸ¥çœ‹æ—¥å¿—</summary>

<p>Step 1: Loadingâ€¦<br>Step 2: Trainingâ€¦</p>
</details>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">âœ… 7. LaTeX æ•°å­¦å…¬å¼ï¼ˆTypora / Jupyter æ”¯æŒï¼‰</span><br></pre></td></tr></table></figure>
$$
\text{softmax}(x_i) = \frac{e^{x_i}}{\sum_j e^{x_j}}
$$
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">âœ… 8. æ’å…¥è¶…é“¾æ¥ï¼ˆæ–‡æ¡£å¯¼èˆªï¼‰</span><br></pre></td></tr></table></figure>
[æŸ¥çœ‹å¯¼å‡ºè„šæœ¬](./export_model.py)
```

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/07/27/markdown/" data-id="cmdwxao5x00035ox9g6q609v2" data-title="markdownå°æŠ€å·§" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%B0%8F%E6%8A%80%E5%B7%A7/" rel="tag">å°æŠ€å·§</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-åŸºç¡€çŸ¥è¯†/vitæºç è¯¦è§£" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/07/27/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/vit%E6%BA%90%E7%A0%81%E8%AF%A6%E8%A7%A3/" class="article-date">
  <time class="dt-published" datetime="2025-07-26T16:00:00.000Z" itemprop="datePublished">2025-07-27</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/">åŸºç¡€çŸ¥è¯†</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2025/07/27/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/vit%E6%BA%90%E7%A0%81%E8%AF%A6%E8%A7%A3/">vitæºç è¯¦è§£(linformer)</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="1-ç¯å¢ƒå®‰è£…â•è®­ç»ƒ"><a href="#1-ç¯å¢ƒå®‰è£…â•è®­ç»ƒ" class="headerlink" title="1.ç¯å¢ƒå®‰è£…â•è®­ç»ƒ"></a>1.ç¯å¢ƒå®‰è£…â•è®­ç»ƒ</h1><ul>
<li><p>ä¸‹è½½transformerï¼Œvit-pytorchä¸¤ä¸ªä»£ç ä»“.</p>
  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> git@github.com:huggingface/transformers.git</span><br><span class="line">git <span class="built_in">clone</span> git@github.com:lucidrains/vit-pytorch.git</span><br><span class="line">åˆ†åˆ«ä½¿ç”¨ pip install -e . å¯ä»¥å®‰è£…ä¸Šè¿°ä¸¤ä¸ªä»£ç ä»“</span><br></pre></td></tr></table></figure></li>
<li><p><code>vit-pytorch/examples/cats_and_dogs.ipynb</code>æŒ‰ç…§å†…éƒ¨è¯´æ˜ä¸‹è½½<code>data</code>ã€‚</p>
</li>
<li><p>ä¿®æ”¹jupyteræœ€åä¸€æ­¥çš„è®­ç»ƒä»£ç å¦‚ä¸‹ï¼Œä¿å­˜æœ€ä¼˜æ¨¡å‹ã€‚</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">best_val_acc = <span class="number">0</span></span><br><span class="line">save_path = <span class="string">&quot;model/best_model_vit.pth&quot;</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    epoch_loss = <span class="number">0</span></span><br><span class="line">    epoch_accuracy = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> data, label <span class="keyword">in</span> tqdm(train_loader):</span><br><span class="line">        data = data.to(device)</span><br><span class="line">        label = label.to(device)</span><br><span class="line"></span><br><span class="line">        output = model(data)</span><br><span class="line">        loss = criterion(output, label)</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        acc = (output.argmax(dim=<span class="number">1</span>) == label).<span class="built_in">float</span>().mean()</span><br><span class="line">        epoch_accuracy += acc / <span class="built_in">len</span>(train_loader)</span><br><span class="line">        epoch_loss += loss / <span class="built_in">len</span>(train_loader)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        epoch_val_accuracy = <span class="number">0</span></span><br><span class="line">        epoch_val_loss = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> data, label <span class="keyword">in</span> valid_loader:</span><br><span class="line">            data = data.to(device)</span><br><span class="line">            label = label.to(device)</span><br><span class="line"></span><br><span class="line">            val_output = model(data)</span><br><span class="line">            val_loss = criterion(val_output, label)</span><br><span class="line"></span><br><span class="line">            acc = (val_output.argmax(dim=<span class="number">1</span>) == label).<span class="built_in">float</span>().mean()</span><br><span class="line">            epoch_val_accuracy += acc / <span class="built_in">len</span>(valid_loader)</span><br><span class="line">            epoch_val_loss += val_loss / <span class="built_in">len</span>(valid_loader)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># âœ… 5. æ¨¡å‹ä¿å­˜ï¼ˆval acc æœ€ä¼˜ï¼‰</span></span><br><span class="line">    <span class="keyword">if</span> epoch_val_accuracy &gt; best_val_acc:</span><br><span class="line">        torch.save(model.state_dict(), save_path)</span><br><span class="line">        best_val_acc = epoch_val_accuracy</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(</span><br><span class="line">        <span class="string">f&quot;Epoch : <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span> - loss : <span class="subst">&#123;epoch_loss:<span class="number">.4</span>f&#125;</span> - acc: <span class="subst">&#123;epoch_accuracy:<span class="number">.4</span>f&#125;</span> - val_loss : <span class="subst">&#123;epoch_val_loss:<span class="number">.4</span>f&#125;</span> - val_acc: <span class="subst">&#123;epoch_val_accuracy:<span class="number">.4</span>f&#125;</span>\n&quot;</span></span><br><span class="line">    )</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>è¿è¡Œjupyterï¼Œå¾—åˆ°æœ€ç»ˆæ¨¡å‹<code>best_model_vit.pth</code>ã€‚</p>
</li>
</ul>
<h1 id="2-æºç è§£è¯»"><a href="#2-æºç è§£è¯»" class="headerlink" title="2.æºç è§£è¯»"></a>2.æºç è§£è¯»</h1><ul>
<li>æ€»æ•°æ®æµ  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">image â†’ patch â†’ embedding â†’ +CLS â†’ +PE</span><br><span class="line">    â†“</span><br><span class="line">Transformer encoder</span><br><span class="line">    â†“</span><br><span class="line">å– [CLS] or Mean</span><br><span class="line">    â†“</span><br><span class="line">Linear â†’ MLP head â†’ åˆ†ç±» logits </span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="2-1-æ•°æ®é¢„å¤„ç†"><a href="#2-1-æ•°æ®é¢„å¤„ç†" class="headerlink" title="2.1 æ•°æ®é¢„å¤„ç†"></a>2.1 æ•°æ®é¢„å¤„ç†</h2><ul>
<li>å°†ä¸€å¼ å›¾ç‰‡ä» [batch, channel, height, width] è½¬æ¢ä¸º [batch, num_patches, dim] çš„å½¢å¼  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">image_height, image_width = pair(image_size)<span class="comment">#åŸå§‹å›¾ç‰‡å¤§å°</span></span><br><span class="line">patch_height, patch_width = pair(patch_size)<span class="comment">#æ¯ä¸ªpatchçš„é•¿å®½</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">assert</span> image_height % patch_height == <span class="number">0</span> <span class="keyword">and</span> image_width % patch_width == <span class="number">0</span>, <span class="string">&#x27;Image dimensions must be divisible by the patch size.&#x27;</span></span><br><span class="line"></span><br><span class="line">num_patches = (image_height // patch_height) * (image_width // patch_width) <span class="comment">#ä¸€å¼ å›¾ç‰‡è¢«åˆ†ä¸ºå¤šå°‘ä¸ªpatch</span></span><br><span class="line">patch_dim = channels * patch_height * patch_width <span class="comment">#æ¯ä¸ªpatchçš„ç»´åº¦</span></span><br><span class="line"><span class="keyword">assert</span> pool <span class="keyword">in</span> &#123;<span class="string">&#x27;cls&#x27;</span>, <span class="string">&#x27;mean&#x27;</span>&#125;, <span class="string">&#x27;pool type must be either cls (cls token) or mean (mean pooling)&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="variable language_">self</span>.to_patch_embedding = nn.Sequential(</span><br><span class="line">            Rearrange(<span class="string">&#x27;b c (h p1) (w p2) -&gt; b (h w) (p1 p2 c)&#x27;</span>, p1 = patch_height, p2 = patch_width),</span><br><span class="line">            nn.LayerNorm(patch_dim),</span><br><span class="line">            nn.Linear(patch_dim, dim),</span><br><span class="line">            nn.LayerNorm(dim),</span><br><span class="line">            )<span class="comment">## imgè½¬æ¢æˆpatchåç»è¿‡embeddingå˜æˆ[batch,num_patchs,dim]å¤§å°çš„æ•°æ®</span></span><br></pre></td></tr></table></figure></li>
<li>forwardå¦‚ä¸‹ï¼š  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x = <span class="variable language_">self</span>.to_patch_embedding(img)<span class="comment">#img æŒ‰ç…§åˆ‡å—å„¿çš„æ–¹å¼è½¬æ¢æˆembedding</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="2-2-æ•°æ®embedding-post-embedding"><a href="#2-2-æ•°æ®embedding-post-embedding" class="headerlink" title="2.2 æ•°æ®embedding + post embedding"></a>2.2 æ•°æ®embedding + post embedding</h2><ul>
<li><p>init</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">è¾“å…¥ï¼š              patch_1  patch_2  ...  patch_n</span><br><span class="line">                    â†“        â†“             â†“</span><br><span class="line">æ‹¼æ¥ï¼š    [CLS]    patch_1  patch_2  ...  patch_n</span><br><span class="line">            â†“        â†“        â†“             â†“</span><br><span class="line">ä½ç½®ç¼–ç ï¼š +PE_0    +PE_1    +PE_2        +PE_n</span><br><span class="line">            â†“        â†“        â†“             â†“</span><br><span class="line">è¾“å…¥ï¼š  [CLS+PE_0, patch_1+PE_1, ..., patch_n+PE_n]</span><br><span class="line"></span><br><span class="line"><span class="variable language_">self</span>.pos_embedding = nn.Parameter(torch.randn(<span class="number">1</span>, num_patches + <span class="number">1</span>, dim)) <span class="comment">#+1ï¼Œæ˜¯å› ä¸ºè¿˜è¦åŠ ä¸Šä¸€ä¸ª [CLS] tokenï¼›dimé€šå¸¸ä¸º768</span></span><br><span class="line"><span class="variable language_">self</span>.cls_token = nn.Parameter(torch.randn(<span class="number">1</span>, <span class="number">1</span>, dim))<span class="comment">#è¿™æ˜¯ ViT æ¨¡ä»¿ NLP ä¸­ BERT çš„åšæ³•ï¼Œåœ¨æœ€å‰é¢æ·»åŠ ä¸€ä¸ªâ€œå…¨å±€æ‘˜è¦â€ç”¨çš„ tokenã€‚</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>forwardå¦‚ä¸‹ï¼š</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">b, n, _ = x.shape</span><br><span class="line"></span><br><span class="line">cls_tokens = repeat(<span class="variable language_">self</span>.cls_token, <span class="string">&#x27;1 1 d -&gt; b 1 d&#x27;</span>, b = b)</span><br><span class="line">x = torch.cat((cls_tokens, x), dim=<span class="number">1</span>) <span class="comment">#æŠŠ [CLS] token æ‹¼æ¥åˆ°æ¯ä¸ªå›¾åƒ patch åºåˆ—çš„æœ€å‰é¢ã€‚</span></span><br><span class="line">x += <span class="variable language_">self</span>.pos_embedding[:, :(n + <span class="number">1</span>)] <span class="comment">#ç»™æ¯ä¸ª patch + [CLS] token åŠ ä¸Šå¯¹åº”çš„ ä½ç½®ç¼–ç ï¼›</span></span><br><span class="line">x = <span class="variable language_">self</span>.dropout(x) <span class="comment">#æé«˜æ³›åŒ–èƒ½åŠ›ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆã€‚</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="2-3-transformer"><a href="#2-3-transformer" class="headerlink" title="2.3 transformer"></a>2.3 transformer</h2><ul>
<li>transformerç»“æ„<ul>
<li><p><code>layers = [ (PreNorm(attn_1), PreNorm(ff_1)), (PreNorm(attn_2), PreNorm(ff_2)), ... ]   </code><br>è¿™ä¸ªæ˜¯layerçš„ç»“æ„ï¼Œæ¯ä¸ªç»“æ„ä¹‹å‰å…ˆè¿‡ä¸€ä¸ªprenormï¼Œ<code>x = self.norm(x) return self.fn(x)</code><br>æ•´ä½“æ•°æ®æµå¦‚ä¸‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">SequentialSequenceï¼šx = x + attn(x) x = x + ffn(x)</span><br><span class="line"><span class="built_in">input</span> x</span><br><span class="line">â†“</span><br><span class="line">(attn_1 â†’ ff_1) <span class="keyword">with</span> residual</span><br><span class="line">â†“</span><br><span class="line">(attn_2 â†’ ff_2)</span><br><span class="line">â†“</span><br><span class="line">...</span><br><span class="line">â†“</span><br><span class="line">(attn_n â†’ ff_n)</span><br><span class="line">â†“</span><br><span class="line">output</span><br><span class="line"></span><br><span class="line"><span class="comment">##æ ‘å½¢æ•°æ®æµ</span></span><br><span class="line">Transformer Block</span><br><span class="line">â”œâ”€â”€ Multi-Head Attention</span><br><span class="line">â”‚    â””â”€â”€ Residual + LayerNorm</span><br><span class="line">â”œâ”€â”€ FeedForward</span><br><span class="line">â”‚    â”œâ”€â”€ Linear1 (dim â†’ dim*<span class="number">4</span>)</span><br><span class="line">â”‚    â”œâ”€â”€ GELU</span><br><span class="line">â”‚    â”œâ”€â”€ Dropout</span><br><span class="line">â”‚    â”œâ”€â”€ Linear2 (dim*<span class="number">4</span> â†’ dim)</span><br><span class="line">â”‚    â””â”€â”€ Residual + LayerNorm</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Linformer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, seq_len, depth, k = <span class="number">256</span>, heads = <span class="number">8</span>, dim_head = <span class="literal">None</span>, one_kv_head = <span class="literal">False</span>, share_kv = <span class="literal">False</span>, reversible = <span class="literal">False</span>, dropout = <span class="number">0.</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        layers = nn.ModuleList([])</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(depth):</span><br><span class="line">            attn = LinformerSelfAttention(dim, seq_len, k = k, heads = heads, dim_head = dim_head, one_kv_head = one_kv_head, share_kv = share_kv, dropout = dropout)</span><br><span class="line">            ff = FeedForward(dim, dropout = dropout)</span><br><span class="line"></span><br><span class="line">            layers.append(nn.ModuleList([</span><br><span class="line">                PreNorm(dim, attn),</span><br><span class="line">                PreNorm(dim, ff)</span><br><span class="line">            ]))</span><br><span class="line"></span><br><span class="line">        execute_type = ReversibleSequence <span class="keyword">if</span> reversible <span class="keyword">else</span> SequentialSequence</span><br><span class="line">        <span class="variable language_">self</span>.net = execute_type(layers)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.net(x)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>attentionç»“æ„<ul>
<li>linformeré€šè¿‡ä½ç§©ç©ºé—´çš„æ˜ å°„ï¼Œä½¿å…¶ä» O(nÂ²) é™ä¸º O(nÂ·k)ï¼Œå…¶ä¸­ k â‰ª nã€‚ä¸»è¦ç»“æ„ä¸ºProj_kã€‚</li>
<li>linformerç»“æ„æ•°æ®æµå¦‚ä¸‹ï¼š             <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">     â†“ to_q (Linear)</span><br><span class="line">Input x â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Q</span><br><span class="line">      â†“ to_k/v (Linear)</span><br><span class="line">Input x â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ K, V â†’ einsum(Proj_k/v) â†’ K_proj, V_proj</span><br><span class="line">      â†“</span><br><span class="line"> Multi-head Attention</span><br><span class="line">      â†“</span><br><span class="line">   Output (Linear)</span><br></pre></td></tr></table></figure></li>
<li><code>self.proj_k = nn.Parameter(init_(torch.zeros(seq_len, k)))</code><br>proj_k: æ˜¯å½¢çŠ¶ [seq_len, k] çš„ learnable å‚æ•°ï¼›<br>ç”¨äºå°†åŸå§‹ Key&#x2F;Value æ²¿ç€åºåˆ—ç»´åº¦æŠ•å½±åˆ°æ›´ä½ç»´ç©ºé—´ï¼ˆçº¿æ€§æŠ•å½±çŸ©é˜µï¼‰ï¼›ä¹Ÿå°±æ˜¯å‡å°‘seq_lençš„ç»´åº¦</li>
<li>ä»£ç å¦‚ä¸‹ï¼š<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LinformerSelfAttention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, seq_len, k = <span class="number">256</span>, heads = <span class="number">8</span>, dim_head = <span class="literal">None</span>, one_kv_head = <span class="literal">False</span>, share_kv = <span class="literal">False</span>, dropout = <span class="number">0.</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="keyword">assert</span> (dim % heads) == <span class="number">0</span>, <span class="string">&#x27;dimension must be divisible by the number of heads&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.seq_len = seq_len</span><br><span class="line">        <span class="variable language_">self</span>.k = k</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.heads = heads</span><br><span class="line"></span><br><span class="line">        dim_head = default(dim_head, dim // heads)</span><br><span class="line">        <span class="variable language_">self</span>.dim_head = dim_head</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.to_q = nn.Linear(dim, dim_head * heads, bias = <span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        kv_dim = dim_head <span class="keyword">if</span> one_kv_head <span class="keyword">else</span> (dim_head * heads)</span><br><span class="line">        <span class="variable language_">self</span>.to_k = nn.Linear(dim, kv_dim, bias = <span class="literal">False</span>)</span><br><span class="line">        <span class="variable language_">self</span>.proj_k = nn.Parameter(init_(torch.zeros(seq_len, k)))</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.share_kv = share_kv</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> share_kv:</span><br><span class="line">            <span class="variable language_">self</span>.to_v = nn.Linear(dim, kv_dim, bias = <span class="literal">False</span>)</span><br><span class="line">            <span class="variable language_">self</span>.proj_v = nn.Parameter(init_(torch.zeros(seq_len, k)))</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.dropout = nn.Dropout(dropout)</span><br><span class="line">        <span class="variable language_">self</span>.to_out = nn.Linear(dim_head * heads, dim)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, context = <span class="literal">None</span>, **kwargs</span>):</span><br><span class="line">        b, n, d, d_h, h, k = *x.shape, <span class="variable language_">self</span>.dim_head, <span class="variable language_">self</span>.heads, <span class="variable language_">self</span>.k</span><br><span class="line"></span><br><span class="line">        kv_len = n <span class="keyword">if</span> context <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> context.shape[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">assert</span> kv_len &lt;= <span class="variable language_">self</span>.seq_len, <span class="string">f&#x27;the sequence length of the key / values must be <span class="subst">&#123;self.seq_len&#125;</span> - <span class="subst">&#123;kv_len&#125;</span> given&#x27;</span></span><br><span class="line"></span><br><span class="line">        queries = <span class="variable language_">self</span>.to_q(x)</span><br><span class="line"></span><br><span class="line">        proj_seq_len = <span class="keyword">lambda</span> args: torch.einsum(<span class="string">&#x27;bnd,nk-&gt;bkd&#x27;</span>, *args)</span><br><span class="line"></span><br><span class="line">        kv_input = x <span class="keyword">if</span> context <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> context</span><br><span class="line"></span><br><span class="line">        keys = <span class="variable language_">self</span>.to_k(kv_input)</span><br><span class="line">        values = <span class="variable language_">self</span>.to_v(kv_input) <span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.share_kv <span class="keyword">else</span> keys</span><br><span class="line"></span><br><span class="line">        kv_projs = (<span class="variable language_">self</span>.proj_k, <span class="variable language_">self</span>.proj_v <span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.share_kv <span class="keyword">else</span> <span class="variable language_">self</span>.proj_k)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># allow for variable sequence lengths (less than maximum sequence length) by slicing projections</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> kv_len &lt; <span class="variable language_">self</span>.seq_len:</span><br><span class="line">            kv_projs = <span class="built_in">map</span>(<span class="keyword">lambda</span> t: t[:kv_len], kv_projs)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># project keys and values along the sequence length dimension to k</span></span><br><span class="line">        <span class="comment"># å¯¹ key/value åšä½ç§©æŠ•å½±</span></span><br><span class="line">        keys, values = <span class="built_in">map</span>(proj_seq_len, <span class="built_in">zip</span>((keys, values), kv_projs))<span class="comment">#map(åŠŸèƒ½ï¼Œè¾“å…¥) zip()-&gt;ï¼ˆkï¼Œproj_kï¼‰ï¼ˆv,proj_vï¼‰</span></span><br><span class="line">        <span class="comment">#[b,k,d][b,k,d]</span></span><br><span class="line">        <span class="comment"># merge head into batch for queries and key / values</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># queries â†’ reshape + transpose â†’ [b, h, n, d_h]</span></span><br><span class="line">        <span class="comment"># keys/values â†’ reshape â†’ [b, h, k, d_h]</span></span><br><span class="line">        queries = queries.reshape(b, n, h, -<span class="number">1</span>).transpose(<span class="number">1</span>, <span class="number">2</span>)<span class="comment">#[b,n,d]-&gt;[b,n,h,h_d]-&gt;[b,h,n,h_d]</span></span><br><span class="line"></span><br><span class="line">        merge_key_values = <span class="keyword">lambda</span> t: t.reshape(b, k, -<span class="number">1</span>, d_h).transpose(<span class="number">1</span>, <span class="number">2</span>).expand(-<span class="number">1</span>, h, -<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">        keys, values = <span class="built_in">map</span>(merge_key_values, (keys, values)) <span class="comment">#map(åŠŸèƒ½ï¼Œè¾“å…¥)[b,k,d]-&gt;[b,k,h,h_d]-&gt;[b,h,k,h_d]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># attention</span></span><br><span class="line"></span><br><span class="line">        dots = torch.einsum(<span class="string">&#x27;bhnd,bhkd-&gt;bhnk&#x27;</span>, queries, keys) * (d_h ** -<span class="number">0.5</span>) <span class="comment">#å¤æ‚åº¦æ˜¯nkdï¼Œflops=æ¯ä¸ªä½ç½®æ˜¯ä¸€ä¸ªå‘é‡ç‚¹ä¹˜ï¼Œæ¯ä¸ªä½ç½®éœ€è¦ d_h æ¬¡ä¹˜åŠ ï¼Œä¸€å…±b*n*hä¸ªä½ç½®ï¼Œæ‰€ä»¥æ˜¯2dhnkd</span></span><br><span class="line">        attn = dots.softmax(dim=-<span class="number">1</span>)</span><br><span class="line">        attn = <span class="variable language_">self</span>.dropout(attn)</span><br><span class="line">        out = torch.einsum(<span class="string">&#x27;bhnk,bhkd-&gt;bhnd&#x27;</span>, attn, values)<span class="comment">#å¤æ‚åº¦æ˜¯ndkï¼Œflopsæ˜¯b*h*n*dä¸ªä½ç½®ï¼Œæ¯ä¸ªä½ç½®kæ¬¡ä¹˜åŠ ï¼Œæ‰€ä»¥æ˜¯2dhnkd</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># split heads</span></span><br><span class="line">        out = out.transpose(<span class="number">1</span>, <span class="number">2</span>).reshape(b, n, -<span class="number">1</span>)<span class="comment">#bhnd_n-&gt;bnhd_n-&gt;bnd</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.to_out(out)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>ffnç»“æ„ï¼ˆfeedforwardï¼‰<ul>
<li><p>ä¸¤å±‚ Linear + æ¿€æ´» + Dropout</p>
</li>
<li><p>å¼•å…¥é—¨æ§æœºåˆ¶GLUï¼š <code>act(x) * v  ä¹Ÿå°±æ˜¯  GELU(x)*v</code></p>
</li>
<li><p>geluçš„åŸç†ï¼š<br>$<br>\text{GELU}(x) &#x3D; x \cdot \Phi(x)<br>$<br>æ ‡å‡†æ­£æ€åˆ†å¸ƒçš„ç´¯ç§¯åˆ†å¸ƒå‡½æ•°çš„è¿‘ä¼¼å®ç°ï¼š<br>$\text{GELU}(x) \approx 0.5 \cdot x \cdot \left(1 + \tanh\left( \sqrt{\frac{2}{\pi}} \cdot (x + 0.044715 x^3) \right) \right)$<br>å®ç°äº† é«˜æ–¯æ¦‚ç‡åŠ æƒçš„ xï¼ˆç›¸å½“äºæŸ”å’Œè¿‡æ¸¡ï¼‰</p>
</li>
<li><p>æ•°æ®æµå¦‚ä¸‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##æ­£å¸¸ç‰ˆæœ¬æ•°æ®æµ</span></span><br><span class="line">x â†’ Linear(dim, dim*<span class="number">4</span>) [B, L, D][B, L, D*<span class="number">4</span>] æ‰©å¤§ç‰¹å¾ç»´åº¦</span><br><span class="line">    â†’ GELU / ReLU / SiLU [B, L, D*<span class="number">4</span>][B, L, D*<span class="number">4</span>] éçº¿æ€§å˜æ¢</span><br><span class="line">    â†’ Dropout [B, L, D*<span class="number">4</span>][B, L, D*<span class="number">4</span>] æ­£åˆ™åŒ–</span><br><span class="line">    â†’ Linear(dim*<span class="number">4</span>, dim) [B, L, D*<span class="number">4</span>][B, L, D] æ˜ å°„å›åŸå§‹ç»´åº¦</span><br><span class="line">    â†’ Residual + LayerNorm</span><br><span class="line"><span class="comment">#GLUç‰ˆæœ¬æ•°æ®æµ</span></span><br><span class="line">x â†’ Linear(dim, dim*<span class="number">8</span>)  â†’ chunk æˆ x1, x2</span><br><span class="line">    x1 â†’ æ¿€æ´»(x1)</span><br><span class="line">    out = x1 * x2 <span class="comment">#GLU</span></span><br><span class="line">    â†’ Dropout â†’ Linear(dim*<span class="number">4</span>, dim)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GELU_</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.5</span> * x * (<span class="number">1</span> + torch.tanh(math.sqrt(<span class="number">2</span> / math.pi) * (x + <span class="number">0.044715</span> * torch.<span class="built_in">pow</span>(x, <span class="number">3</span>))))</span><br><span class="line"></span><br><span class="line">GELU = nn.GELU <span class="keyword">if</span> <span class="built_in">hasattr</span>(nn, <span class="string">&#x27;GELU&#x27;</span>) <span class="keyword">else</span> GELU_</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FeedForward</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, mult = <span class="number">4</span>, dropout = <span class="number">0.</span>, activation = <span class="literal">None</span>, glu = <span class="literal">False</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        activation = default(activation, GELU)</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.glu = glu</span><br><span class="line">        <span class="variable language_">self</span>.w1 = nn.Linear(dim, dim * mult * (<span class="number">2</span> <span class="keyword">if</span> glu <span class="keyword">else</span> <span class="number">1</span>))</span><br><span class="line">        <span class="variable language_">self</span>.act = activation()</span><br><span class="line">        <span class="variable language_">self</span>.dropout = nn.Dropout(dropout)</span><br><span class="line">        <span class="variable language_">self</span>.w2 = nn.Linear(dim * mult, dim)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, **kwargs</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.glu:</span><br><span class="line">            x = <span class="variable language_">self</span>.w1(x)</span><br><span class="line">            x = <span class="variable language_">self</span>.act(x)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            x, v = <span class="variable language_">self</span>.w1(x).chunk(<span class="number">2</span>, dim=-<span class="number">1</span>)</span><br><span class="line">            x = <span class="variable language_">self</span>.act(x) * v</span><br><span class="line"></span><br><span class="line">        x = <span class="variable language_">self</span>.dropout(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.w2(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<h2 id="2-4-åˆ†ç±»è¾“å‡º"><a href="#2-4-åˆ†ç±»è¾“å‡º" class="headerlink" title="2.4 åˆ†ç±»è¾“å‡º"></a>2.4 åˆ†ç±»è¾“å‡º</h2><ul>
<li>forwardéƒ¨åˆ†å¦‚ä¸‹ï¼š  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># é€šå¸¸ [CLS] token æœ€åç”¨äºåšåˆ†ç±»ä»»åŠ¡çš„è¾“å‡º headï¼ˆç±»ä¼¼ BERTï¼‰ã€‚</span></span><br><span class="line">x = x.mean(dim = <span class="number">1</span>) <span class="keyword">if</span> <span class="variable language_">self</span>.pool == <span class="string">&#x27;mean&#x27;</span> <span class="keyword">else</span> x[:, <span class="number">0</span>] <span class="comment">#å¯¹æ‰€æœ‰ tokenï¼ˆåŒ…æ‹¬ patch å’Œ CLSï¼‰å–å¹³å‡ï¼›</span></span><br><span class="line"><span class="comment"># å¦åˆ™å– [CLS] tokenï¼Œå³ x[:, 0]ï¼›</span></span><br><span class="line"></span><br><span class="line">x = <span class="variable language_">self</span>.to_latent(x)</span><br><span class="line">out = <span class="variable language_">self</span>.mlp_head(x)</span><br><span class="line"><span class="keyword">return</span> out</span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="3-onnxå¯¼å‡º"><a href="#3-onnxå¯¼å‡º" class="headerlink" title="3.onnxå¯¼å‡º"></a>3.onnxå¯¼å‡º</h1><ul>
<li>onnxå¯¼å‡ºåªéœ€è¦åœ¨exampleåŠ è½½åŸæ¥ä¿å­˜çš„æ¨¡å‹ï¼Œç„¶åå¯¼å‡ºã€‚  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># âœ… 6. å¯¼å‡º ONNX æ¨¡å‹</span></span><br><span class="line">model.load_state_dict(torch.load(<span class="string">&quot;model/best_model_vit.pth&quot;</span>, map_location=<span class="string">&quot;cpu&quot;</span>))  <span class="comment"># æ›¿æ¢ä¸ºä½ çš„è·¯å¾„</span></span><br><span class="line">dummy_input = torch.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>).to(device)</span><br><span class="line">model.to(device).<span class="built_in">eval</span>()</span><br><span class="line">torch.onnx.export(</span><br><span class="line">    model.module <span class="keyword">if</span> <span class="built_in">isinstance</span>(model, nn.DataParallel) <span class="keyword">else</span> model,</span><br><span class="line">    dummy_input,</span><br><span class="line">    <span class="string">&quot;model/final_model_vit.onnx&quot;</span>,</span><br><span class="line">    input_names=[<span class="string">&quot;input&quot;</span>],</span><br><span class="line">    output_names=[<span class="string">&quot;output&quot;</span>],</span><br><span class="line">    opset_version=<span class="number">16</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<ul>
<li>å¯ä»¥ç”¨netronæŸ¥çœ‹æ¨¡å‹ç»“æ„ã€‚<br><img src="/./jpg/onnx-vit.jpg" alt="vit-onnx"></li>
</ul>
</li>
</ul>
<h1 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h1><ul>
<li>tensorrtç¼–è¯‘æµ‹é€Ÿ</li>
<li>profilingåˆ†æ</li>
<li>è‡ªå®šä¹‰layernorm</li>
<li>é‡åŒ–ç²¾åº¦åˆ†æ</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/07/27/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/vit%E6%BA%90%E7%A0%81%E8%AF%A6%E8%A7%A3/" data-id="cmdwxao65000i5ox9fzde1l9x" data-title="vitæºç è¯¦è§£(linformer)" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Transformer/" rel="tag">Transformer</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/linformer/" rel="tag">linformer</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/vit/" rel="tag">vit</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/vit-pytorch/" rel="tag">vit-pytorch</a></li></ul>

    </footer>
  </div>
  
</article>



  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="page-number current">2</span>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/markdown/">markdown</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%91%A8%E8%AE%A1%E5%88%92/">å‘¨è®¡åˆ’</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/">åŸºç¡€çŸ¥è¯†</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F/">æ¨ç†åŠ é€Ÿ</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/FLOPS/" rel="tag">FLOPS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Transformer/" rel="tag">Transformer</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/attention/" rel="tag">attention</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/conv/" rel="tag">conv</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cuda%E5%8A%A0%E9%80%9F/" rel="tag">cudaåŠ é€Ÿ</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/float/" rel="tag">float</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/img-preprocess/" rel="tag">img_preprocess</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/int/" rel="tag">int</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kv-cache/" rel="tag">kv-cache</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linformer/" rel="tag">linformer</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/profiling/" rel="tag">profiling</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/vit/" rel="tag">vit</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/vit-pytorch/" rel="tag">vit-pytorch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/week1/" rel="tag">week1</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AE%9A%E7%82%B9%E6%95%B0/" rel="tag">å®šç‚¹æ•°</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%B0%8F%E6%8A%80%E5%B7%A7/" rel="tag">å°æŠ€å·§</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8/" rel="tag">æ˜¾å­˜å ç”¨</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B5%AE%E7%82%B9%E6%95%B0/" rel="tag">æµ®ç‚¹æ•°</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%AE%97%E6%B3%95%E5%A4%8D%E6%9D%82%E5%BA%A6/" rel="tag">ç®—æ³•å¤æ‚åº¦</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%BF%90%E7%AE%97%E9%87%8F/" rel="tag">è¿ç®—é‡</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/FLOPS/" style="font-size: 10px;">FLOPS</a> <a href="/tags/Transformer/" style="font-size: 10px;">Transformer</a> <a href="/tags/attention/" style="font-size: 20px;">attention</a> <a href="/tags/conv/" style="font-size: 10px;">conv</a> <a href="/tags/cuda%E5%8A%A0%E9%80%9F/" style="font-size: 20px;">cudaåŠ é€Ÿ</a> <a href="/tags/float/" style="font-size: 10px;">float</a> <a href="/tags/img-preprocess/" style="font-size: 10px;">img_preprocess</a> <a href="/tags/int/" style="font-size: 10px;">int</a> <a href="/tags/kv-cache/" style="font-size: 10px;">kv-cache</a> <a href="/tags/linformer/" style="font-size: 10px;">linformer</a> <a href="/tags/profiling/" style="font-size: 10px;">profiling</a> <a href="/tags/vit/" style="font-size: 20px;">vit</a> <a href="/tags/vit-pytorch/" style="font-size: 20px;">vit-pytorch</a> <a href="/tags/week1/" style="font-size: 10px;">week1</a> <a href="/tags/%E5%AE%9A%E7%82%B9%E6%95%B0/" style="font-size: 10px;">å®šç‚¹æ•°</a> <a href="/tags/%E5%B0%8F%E6%8A%80%E5%B7%A7/" style="font-size: 10px;">å°æŠ€å·§</a> <a href="/tags/%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8/" style="font-size: 10px;">æ˜¾å­˜å ç”¨</a> <a href="/tags/%E6%B5%AE%E7%82%B9%E6%95%B0/" style="font-size: 10px;">æµ®ç‚¹æ•°</a> <a href="/tags/%E7%AE%97%E6%B3%95%E5%A4%8D%E6%9D%82%E5%BA%A6/" style="font-size: 10px;">ç®—æ³•å¤æ‚åº¦</a> <a href="/tags/%E8%BF%90%E7%AE%97%E9%87%8F/" style="font-size: 10px;">è¿ç®—é‡</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/07/">July 2025</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2025/07/31/%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F/kvcache/">kv-cache-æºç è§£è¯»</a>
          </li>
        
          <li>
            <a href="/2025/07/31/tensorrt-plugin/">tensorrt-plugin</a>
          </li>
        
          <li>
            <a href="/2025/07/31/%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F/cuda%E4%BC%98%E5%8C%96%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/">resize_cuda</a>
          </li>
        
          <li>
            <a href="/2025/07/31/%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F/resize-cuda/">resize_cuda</a>
          </li>
        
          <li>
            <a href="/2025/07/30/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%84%9F%E7%9F%A5%E9%A2%84%E5%A4%84%E7%90%86/">img_preproc</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2025 sunhanyu<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>