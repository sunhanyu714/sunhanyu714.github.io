<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Sunhanyu-Learning</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="Sunhanyu-Learning">
<meta property="og:url" content="http://example.com/page/2/index.html">
<meta property="og:site_name" content="Sunhanyu-Learning">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="sunhanyu">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Sunhanyu-Learning" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/fork-awesome@1.2.0/css/fork-awesome.min.css">

<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Sunhanyu-Learning</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-周计划/Week2" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/07/28/%E5%91%A8%E8%AE%A1%E5%88%92/Week2/" class="article-date">
  <time class="dt-published" datetime="2025-07-28T05:16:29.000Z" itemprop="datePublished">2025-07-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2025/07/28/%E5%91%A8%E8%AE%A1%E5%88%92/Week2/">Week2</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/07/28/%E5%91%A8%E8%AE%A1%E5%88%92/Week2/" data-id="cmdwxao6100085ox99w7c6dar" data-title="Week2" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-周计划/Week1" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/07/28/%E5%91%A8%E8%AE%A1%E5%88%92/Week1/" class="article-date">
  <time class="dt-published" datetime="2025-07-28T05:16:04.000Z" itemprop="datePublished">2025-07-28</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E5%91%A8%E8%AE%A1%E5%88%92/">周计划</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2025/07/28/%E5%91%A8%E8%AE%A1%E5%88%92/Week1/">Week1</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h3 id="day1-20250728"><a href="#day1-20250728" class="headerlink" title="day1-20250728"></a>day1-20250728</h3><ul>
<li><input checked="" disabled="" type="checkbox"> vit-attention onnx导出</li>
<li><input checked="" disabled="" type="checkbox"> 生成 PyTorch Profiler 脚本；导出可视化图表（如 chrome trace、timeline 图）；</li>
<li><input checked="" disabled="" type="checkbox"> 修改不同的attention版本查看profiling的变化。</li>
</ul>
<h3 id="day2-20250729"><a href="#day2-20250729" class="headerlink" title="day2-20250729"></a>day2-20250729</h3><ul>
<li><input checked="" disabled="" type="checkbox"> 计算模型的flops，参数量和显存占用</li>
</ul>
<h3 id="day3-20250730"><a href="#day3-20250730" class="headerlink" title="day3-20250730"></a>day3-20250730</h3><ul>
<li><input checked="" disabled="" type="checkbox"> 熟悉工程的pipline-笔记在notion</li>
<li><input checked="" disabled="" type="checkbox"> kv cache的源码如何实现的？qkv相乘如何做的？</li>
</ul>
<h3 id="day4-20250731"><a href="#day4-20250731" class="headerlink" title="day4-20250731"></a>day4-20250731</h3><ul>
<li><input disabled="" type="checkbox"> 学习后处理的nms，iou计算等算法的c++实现。</li>
<li><input disabled="" type="checkbox"> 学习前处理加速算子如何实现(cuda实现)</li>
<li><input disabled="" type="checkbox"> 在vit模型基础上构建一个 attention 子图拆解 Demo（TensorRT）；</li>
<li><input disabled="" type="checkbox"> 先转换vit为trt模型，看看有哪些算子被fallback cpu，在进行实现。其中还要看看trt如何转engine，除了命令行。python如何转换呢？</li>
<li><input disabled="" type="checkbox"> 对比tensort int8 fp16 fp32的实际flops，以及profiling。</li>
<li><input disabled="" type="checkbox"> 用 trtexec 分析模型每层耗时，Nsight Compute 分析 LayerNorm 的瓶颈。自定义tensorrt的layernorm之后，测试profiling有没有变化。</li>
<li><input disabled="" type="checkbox"> 算法题刷题（704. 二分查找 27.移除元素）</li>
</ul>
<h3 id="后续计划"><a href="#后续计划" class="headerlink" title="后续计划"></a>后续计划</h3><ul>
<li><input disabled="" type="checkbox"> tensorrt部署vit和qwen模型</li>
<li><input disabled="" type="checkbox"> 测试上述量化精度并优化量化精度</li>
<li><input disabled="" type="checkbox"> 芯片底层如何实现的矩阵乘和卷积，我该如何加速？</li>
<li><input disabled="" type="checkbox"> tensorrt plugin 实现 <a target="_blank" rel="noopener" href="https://github.com/TrojanXu/onnxparser-trt-plugin-sample">https://github.com/TrojanXu/onnxparser-trt-plugin-sample</a></li>
<li><input disabled="" type="checkbox"> 除了优化模型结构，还能从cache和flash attention的方向优化模型的推理速度。(使用hungging face和vllm测试)</li>
<li><input disabled="" type="checkbox"> c++八股文</li>
<li><input disabled="" type="checkbox"> 模型部署八股文学习</li>
<li><input disabled="" type="checkbox"> 整理学习知识点</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/07/28/%E5%91%A8%E8%AE%A1%E5%88%92/Week1/" data-id="cmdwxao6000075ox983roa88h" data-title="Week1" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/week1/" rel="tag">week1</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-基础知识/flops和计算复杂度" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/07/28/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/flops%E5%92%8C%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E5%BA%A6/" class="article-date">
  <time class="dt-published" datetime="2025-07-27T16:00:00.000Z" itemprop="datePublished">2025-07-28</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/">基础知识</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2025/07/28/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/flops%E5%92%8C%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E5%BA%A6/">vit源码详解(linformer)</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="1-什么是FLOPs？"><a href="#1-什么是FLOPs？" class="headerlink" title="1.什么是FLOPs？"></a>1.什么是FLOPs？</h1><p>FLOPs（floating point operations）是计算机科学中的一个概念，表示一个计算设备（如CPU或GPU）执行单个运算所需的浮点运算次数。</p>
<p>如attention中的Q.shape&#x3D;[B, N, C]，K.shape&#x3D;[B, N, C]，V.shape&#x3D;[B, N, C]，那么Q<em>K.T.shape&#x3D;[B, N, N]，那么Q</em>K.T的FLOPs为B<em>N</em>N<em>C</em>2,具体解释为最终计算后的shape为[B, N, N]，那么N<em>N个位置进行2</em>C的乘加运算，B次。</p>
<h1 id="2-什么是算法复杂度？"><a href="#2-什么是算法复杂度？" class="headerlink" title="2.什么是算法复杂度？"></a>2.什么是算法复杂度？</h1><p>算法复杂度（Algorithm Complexity）是计算机科学中的一个概念，用于描述一个算法的运行效率。<br>算法复杂度通常用Big O notation来表示，比如O(n^2)表示一个算法的时间复杂度为n的平方。<br>如attention中的Q.shape&#x3D;[B, N, C]，K.shape&#x3D;[B, N, C]，V.shape&#x3D;[B, N, C]，那么Q*K.T的算法复杂度为O($N^2C$)</p>
<p>那么，对于长序列来说N就是瓶颈，对于短序列来说C也就是隐藏层的维度就是瓶颈。</p>
<h1 id="3-float量化成int减少的是什么？"><a href="#3-float量化成int减少的是什么？" class="headerlink" title="3.float量化成int减少的是什么？"></a>3.float量化成int减少的是什么？</h1><ul>
<li>减少的内存占用和内存带宽压力</li>
<li>float32 4个字节 int4 0.5个字节 节省显存87.5% </li>
<li>int4的mac计算次数不会变化，但是单次的mac计算的消耗更低。</li>
</ul>
<h1 id="4-参数量，显存占用和运算量的区别"><a href="#4-参数量，显存占用和运算量的区别" class="headerlink" title="4.参数量，显存占用和运算量的区别"></a>4.参数量，显存占用和运算量的区别</h1><ul>
<li>参数量：参数数量，即模型中可训练的参数数量。以某层的 Query 权重矩阵 W_q 为例，输入维度是 d&#x3D;4096，输出也是 d_k&#x3D;4096，那么参数量为 4096 * 4096 &#x3D; 16,777,216 约等于 1.68M。</li>
<li>显存占用：模型运行时在显存的占用量。除了模型每层的权重矩阵参数需要显存占用外，还要考虑每层attention的中间输出（activations），还有attention中保存的 Key&#x2F;Value 用于加速解码。<ul>
<li>权重参数占用：以fp16为例子，7B模型参数占用为：7B ✖️ 2  &#x3D; 14B</li>
<li>KV占用：（layers * batch_size * seq_len * hidden_size） * 2）* 2B</li>
</ul>
</li>
<li>运算量（FLOPs）：推理（或训练）所需的浮点运算次数（Floating Point Operations）。一加一乘相当于2FLOPs。</li>
</ul>
<h1 id="5-conv的flops，参数量和显存占用"><a href="#5-conv的flops，参数量和显存占用" class="headerlink" title="5. conv的flops，参数量和显存占用"></a>5. conv的flops，参数量和显存占用</h1><ul>
<li>每个输出位置做一次卷积核的 dot product，每个卷积核的参数个数为 Cin × Kh × Kw，输出大小是 Hout × Wout，一共Cout 个卷积核，那么</li>
<li>FLOPs计算量为：<code>FLOPs = 2 × Cout × Hout × Wout × Cin × Kh × Kw x Batch</code><br>  •Cout: 输出通道数<br>  •Hout, Wout: 输出特征图的高和宽<br>  •Cin: 输入通道数<br>  •Kh, Kw: 卷积核的高和宽（Kernel Height &#x2F; Width）<br>  •2: 表示一次乘法 + 一次加法（MAC 操作算两次 FLOPs）</li>
<li>参数量：每个卷积核大小为：Cin × Kh × Kw，共 C_out 个卷积核 → 总参数量为：<code>Params_conv = C_out × C_in × K × K</code></li>
<li>显存占用：这里的显存占用主要计算的是激活值的占用<code>Memory_conv ≈ Batch × C_out × H_out × W_out × sizeof(float/int)</code><ul>
<li>其中float32占4字节，float16占2个字节，int8占1字节，int4占0.5个字节.</li>
</ul>
</li>
</ul>
<h1 id="6-attention的flops，参数量和显存占用"><a href="#6-attention的flops，参数量和显存占用" class="headerlink" title="6. attention的flops，参数量和显存占用"></a>6. attention的flops，参数量和显存占用</h1><ul>
<li>输入维度：B × L × D（batch, seq_len, embedding_dim）</li>
<li>假设用标准 QKV 注意力机制，head 数为 H，每个 head 维度为 d &#x3D; D &#x2F; H</li>
<li>主要包含四个线性层：QKV+输出映射，一个layernorm层可学习参数的参数量为2D，线性层的bias的参数量为D-&gt;4D</li>
<li>参数量：<code>Params_attn = 3 × D × D [+ D × D]≈ 4 × D × D + 6D</code></li>
<li>FLOPS主要来源四个线性层的计算和Q<em>K，A</em>V的计算</li>
<li>FLOPS：<code>FLOPs_attn = 4 × Batch x 2 x D × D x L + Batch x 2 × D × L x L + Batch x 2 × D × L x L</code></li>
<li>显存占用：<ul>
<li>attention的显存占用包括QKV的输入x，占用显存大小为2BLD。</li>
<li>QK计算的输入Q，K，占用显存大小为4BLD，</li>
<li>softmax计算保存QK的结果2BL^2a,其中a指的是head的数量。</li>
<li>softmax后的dropout需要一个QK维度相同的矩阵，占用显存大小为BL^2a，因为mask矩阵的占用字节数为1 bytes。</li>
<li>A*V的输入A，V，占用显存大小为2BL^2a+2BLD。</li>
<li>最后计算输出映射需要保存输入，占用显存大小为2BLD。再加上dropout矩阵，占用显存大小为BLD。</li>
<li>最终中间激活占用的显存大小为11BLD+5BL^2a。</li>
<li>还有一个layer norm，输入的占用显存大小为2BLD。</li>
</ul>
</li>
</ul>
<h1 id="7-MLP的flops，参数量和显存占用"><a href="#7-MLP的flops，参数量和显存占用" class="headerlink" title="7. MLP的flops，参数量和显存占用"></a>7. MLP的flops，参数量和显存占用</h1><ul>
<li>输入维度：B × L × D（batch, seq_len, embedding_dim）</li>
<li>假设用标准 MLP 映射，hidden_dim 为 4*D</li>
<li>主要包括两个线性层：升维+降维，一个layernorm层可学习参数的参数量为2D，线性层的bias的参数量为D+4D</li>
<li>参数量：<code>Params_mlp = 2 × D × hidden_dim ≈ 8 × D × D +7D</code></li>
<li>FLOPs主要来源两个线性层</li>
<li>FLOPS：<code>FLOPS_mlp = 2 x Batch x 2 × D × hidden_dim x L </code></li>
<li>显存占用：<ul>
<li>第一个线性层需要保存其输入，占用显存大小为2BLD</li>
<li>激活函数需要保存输入，占用显存大小为8BLD</li>
<li>第2个线性层需要保存其输入，占用显存大小为2BLD</li>
<li>dropout需要保存输入，占用显存大小为BLD</li>
<li>最终保存的显存大小为19BLD.</li>
<li>还有一个LayerNorm层，需要保存其输入，占用显存大小为2BLD</li>
</ul>
</li>
</ul>
<h1 id="8-l层transformer的floops，参数量和显存占用"><a href="#8-l层transformer的floops，参数量和显存占用" class="headerlink" title="8. l层transformer的floops，参数量和显存占用"></a>8. l层transformer的floops，参数量和显存占用</h1><ul>
<li>参数量：<code>Params_transformer = Params_attn + Params_mlp ≈ l x (4 × D × D + 8 × D × D) + 13D x l</code>，总计约等于$12lD^2$<br>例如不同的llama，隐藏层的维度不同，模型的参数量也不同。<br>｜实际参数量 ｜隐藏维度h ｜层数l	｜12lh^2｜<br>｜———-｜———｜——–｜——｜<br>｜	6.7B	｜4096	｜32	 ｜6,442,450,944｜<br>｜	13.0B	｜5120	｜40	 ｜12,582,912,000｜<br>｜	32.5B	｜6656	｜60	 ｜31,897,681,920｜<br>｜	65.2B	｜8192	｜80	 ｜64,424,509,440｜</li>
<li>flops ：$FLOPS_{transformer} &#x3D; FLOPS{attn} + FLOPS{mlp} ≈ l(24BLD^2 + 4BL^2D) &#x3D; 24lBLD^2$</li>
<li>flops和参数量之间的关系近似为BL个token需要进行一个乘法一个加法运算&#x3D;2BL。</li>
<li>显存占用：<ul>
<li>transformer层需要保存的中间激活占用显存大小为 $(34BLD+5BL^2a)*l$。</li>
<li>对比一个llama 7b的模型，隐藏层维度D为4096，l&#x3D;32层，序列长度L为2048，a&#x3D;1，那么他的显存占用在不同的batch size下对比：</li>
<li>7b模型的显存占用为14G。</li>
<li>$batchsize &#x3D; 1 -&gt; (34<em>1</em>2048<em>4096+5</em>1<em>2048</em>2048*1)*32&#x3D;306184192×32&#x3D;9797894144&#x3D;9.7G$</li>
<li>$batchsize &#x3D; 3 -&gt; (34<em>3</em>2048<em>4096+5</em>3<em>2048</em>2048*1)*32&#x3D;29393682432&#x3D;29.4G$</li>
<li>$batchsize &#x3D; 32 -&gt; (34<em>32</em>2048<em>4096+5</em>32<em>2048</em>2048*1)*32&#x3D;313532612608&#x3D;313.5G$</li>
<li>如上述计算所示，模型的显存占用随batch size的增大而增大。一次需要通过激活重计算、flash attention等方式优化显存占用。</li>
</ul>
</li>
</ul>
<h1 id="9-KV-cache的显存占用分析"><a href="#9-KV-cache的显存占用分析" class="headerlink" title="9. KV cache的显存占用分析"></a>9. KV cache的显存占用分析</h1><ul>
<li>假设输入序列的长度为n ，输出序列的长度为n，以float16来保存KV cache，那么KV cache的峰值显存占用大小为2<em>2</em>(s+n)<em>B</em>D。这里第一个2表示K&#x2F;V cache，第二个2表示float16占2个bytes。</li>
<li>优化kv cache的显存占用方法有：量化、共享kv等。</li>
</ul>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>[1] <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/624740065?s_r=0">分析transfomer的参数量和计算量以及中间激活、kv cache</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/07/28/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/flops%E5%92%8C%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E5%BA%A6/" data-id="cmdwxao64000g5ox9gl8pa90s" data-title="vit源码详解(linformer)" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/FLOPS/" rel="tag">FLOPS</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/attention/" rel="tag">attention</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/conv/" rel="tag">conv</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8/" rel="tag">显存占用</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%AE%97%E6%B3%95%E5%A4%8D%E6%9D%82%E5%BA%A6/" rel="tag">算法复杂度</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%BF%90%E7%AE%97%E9%87%8F/" rel="tag">运算量</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-hello-world" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/07/27/hello-world/" class="article-date">
  <time class="dt-published" datetime="2025-07-27T08:45:42.879Z" itemprop="datePublished">2025-07-27</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2025/07/27/hello-world/">Hello World</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/07/27/hello-world/" data-id="cmdwxao5u00015ox9eif31ihu" data-title="Hello World" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-markdown" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/07/27/markdown/" class="article-date">
  <time class="dt-published" datetime="2025-07-26T16:00:00.000Z" itemprop="datePublished">2025-07-27</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/markdown/">markdown</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2025/07/27/markdown/">markdown小技巧</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>🧠 程序员常用的 Markdown 小技巧</p>
<p>✅ 1. 高亮代码块</p>
<p>使用三反引号 &#96;&#96;&#96; 标记代码区域，并注明语言，自动语法高亮：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">```python</span><br><span class="line">def hello():</span><br><span class="line">    print(&quot;Hello, Markdown!&quot;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">✅ 2. 任务清单 / Todo 列表</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><input checked="" disabled="" type="checkbox"> 完成模型训练</li>
<li><input disabled="" type="checkbox"> 导出为 ONNX</li>
<li><input disabled="" type="checkbox"> 写好 README</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">✅ 3. 表格快速排列对比信息</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>模型名</th>
<th>精度 Top1</th>
<th>推理时间</th>
</tr>
</thead>
<tbody><tr>
<td>ResNet50</td>
<td>76.5%</td>
<td>12ms</td>
</tr>
<tr>
<td>MobileNetV2</td>
<td>71.8%</td>
<td>5ms</td>
</tr>
</tbody></table>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">✅ 4. 自动编号 / 嵌套列表</span><br></pre></td></tr></table></figure>
<ol>
<li>模型定义<ul>
<li>使用 torch.nn</li>
<li>支持 dropout</li>
</ul>
</li>
<li>导出流程<ul>
<li>ONNX export</li>
<li>验证输出差异</li>
</ul>
</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">✅ 5. 插入图片（支持本地/网络）</span><br></pre></td></tr></table></figure>
<p><img src="/./vit_architecture.png" alt="ViT结构图"></p>
<p>或：</p>
<p><img src="https://example.com/model.png" alt="模型结构图"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">✅ 6. 折叠内容（GitHub 不支持，Typora 支持）</span><br></pre></td></tr></table></figure>
<details>
  <summary>点击展开查看日志</summary>

<p>Step 1: Loading…<br>Step 2: Training…</p>
</details>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">✅ 7. LaTeX 数学公式（Typora / Jupyter 支持）</span><br></pre></td></tr></table></figure>
$$
\text{softmax}(x_i) = \frac{e^{x_i}}{\sum_j e^{x_j}}
$$
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">✅ 8. 插入超链接（文档导航）</span><br></pre></td></tr></table></figure>
[查看导出脚本](./export_model.py)
```

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/07/27/markdown/" data-id="cmdwxao5x00035ox9g6q609v2" data-title="markdown小技巧" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%B0%8F%E6%8A%80%E5%B7%A7/" rel="tag">小技巧</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-基础知识/vit源码详解" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/07/27/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/vit%E6%BA%90%E7%A0%81%E8%AF%A6%E8%A7%A3/" class="article-date">
  <time class="dt-published" datetime="2025-07-26T16:00:00.000Z" itemprop="datePublished">2025-07-27</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/">基础知识</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2025/07/27/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/vit%E6%BA%90%E7%A0%81%E8%AF%A6%E8%A7%A3/">vit源码详解(linformer)</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="1-环境安装➕训练"><a href="#1-环境安装➕训练" class="headerlink" title="1.环境安装➕训练"></a>1.环境安装➕训练</h1><ul>
<li><p>下载transformer，vit-pytorch两个代码仓.</p>
  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> git@github.com:huggingface/transformers.git</span><br><span class="line">git <span class="built_in">clone</span> git@github.com:lucidrains/vit-pytorch.git</span><br><span class="line">分别使用 pip install -e . 可以安装上述两个代码仓</span><br></pre></td></tr></table></figure></li>
<li><p><code>vit-pytorch/examples/cats_and_dogs.ipynb</code>按照内部说明下载<code>data</code>。</p>
</li>
<li><p>修改jupyter最后一步的训练代码如下，保存最优模型。</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">best_val_acc = <span class="number">0</span></span><br><span class="line">save_path = <span class="string">&quot;model/best_model_vit.pth&quot;</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    epoch_loss = <span class="number">0</span></span><br><span class="line">    epoch_accuracy = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> data, label <span class="keyword">in</span> tqdm(train_loader):</span><br><span class="line">        data = data.to(device)</span><br><span class="line">        label = label.to(device)</span><br><span class="line"></span><br><span class="line">        output = model(data)</span><br><span class="line">        loss = criterion(output, label)</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        acc = (output.argmax(dim=<span class="number">1</span>) == label).<span class="built_in">float</span>().mean()</span><br><span class="line">        epoch_accuracy += acc / <span class="built_in">len</span>(train_loader)</span><br><span class="line">        epoch_loss += loss / <span class="built_in">len</span>(train_loader)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        epoch_val_accuracy = <span class="number">0</span></span><br><span class="line">        epoch_val_loss = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> data, label <span class="keyword">in</span> valid_loader:</span><br><span class="line">            data = data.to(device)</span><br><span class="line">            label = label.to(device)</span><br><span class="line"></span><br><span class="line">            val_output = model(data)</span><br><span class="line">            val_loss = criterion(val_output, label)</span><br><span class="line"></span><br><span class="line">            acc = (val_output.argmax(dim=<span class="number">1</span>) == label).<span class="built_in">float</span>().mean()</span><br><span class="line">            epoch_val_accuracy += acc / <span class="built_in">len</span>(valid_loader)</span><br><span class="line">            epoch_val_loss += val_loss / <span class="built_in">len</span>(valid_loader)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># ✅ 5. 模型保存（val acc 最优）</span></span><br><span class="line">    <span class="keyword">if</span> epoch_val_accuracy &gt; best_val_acc:</span><br><span class="line">        torch.save(model.state_dict(), save_path)</span><br><span class="line">        best_val_acc = epoch_val_accuracy</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(</span><br><span class="line">        <span class="string">f&quot;Epoch : <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span> - loss : <span class="subst">&#123;epoch_loss:<span class="number">.4</span>f&#125;</span> - acc: <span class="subst">&#123;epoch_accuracy:<span class="number">.4</span>f&#125;</span> - val_loss : <span class="subst">&#123;epoch_val_loss:<span class="number">.4</span>f&#125;</span> - val_acc: <span class="subst">&#123;epoch_val_accuracy:<span class="number">.4</span>f&#125;</span>\n&quot;</span></span><br><span class="line">    )</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>运行jupyter，得到最终模型<code>best_model_vit.pth</code>。</p>
</li>
</ul>
<h1 id="2-源码解读"><a href="#2-源码解读" class="headerlink" title="2.源码解读"></a>2.源码解读</h1><ul>
<li>总数据流  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">image → patch → embedding → +CLS → +PE</span><br><span class="line">    ↓</span><br><span class="line">Transformer encoder</span><br><span class="line">    ↓</span><br><span class="line">取 [CLS] or Mean</span><br><span class="line">    ↓</span><br><span class="line">Linear → MLP head → 分类 logits </span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="2-1-数据预处理"><a href="#2-1-数据预处理" class="headerlink" title="2.1 数据预处理"></a>2.1 数据预处理</h2><ul>
<li>将一张图片从 [batch, channel, height, width] 转换为 [batch, num_patches, dim] 的形式  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">image_height, image_width = pair(image_size)<span class="comment">#原始图片大小</span></span><br><span class="line">patch_height, patch_width = pair(patch_size)<span class="comment">#每个patch的长宽</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">assert</span> image_height % patch_height == <span class="number">0</span> <span class="keyword">and</span> image_width % patch_width == <span class="number">0</span>, <span class="string">&#x27;Image dimensions must be divisible by the patch size.&#x27;</span></span><br><span class="line"></span><br><span class="line">num_patches = (image_height // patch_height) * (image_width // patch_width) <span class="comment">#一张图片被分为多少个patch</span></span><br><span class="line">patch_dim = channels * patch_height * patch_width <span class="comment">#每个patch的维度</span></span><br><span class="line"><span class="keyword">assert</span> pool <span class="keyword">in</span> &#123;<span class="string">&#x27;cls&#x27;</span>, <span class="string">&#x27;mean&#x27;</span>&#125;, <span class="string">&#x27;pool type must be either cls (cls token) or mean (mean pooling)&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="variable language_">self</span>.to_patch_embedding = nn.Sequential(</span><br><span class="line">            Rearrange(<span class="string">&#x27;b c (h p1) (w p2) -&gt; b (h w) (p1 p2 c)&#x27;</span>, p1 = patch_height, p2 = patch_width),</span><br><span class="line">            nn.LayerNorm(patch_dim),</span><br><span class="line">            nn.Linear(patch_dim, dim),</span><br><span class="line">            nn.LayerNorm(dim),</span><br><span class="line">            )<span class="comment">## img转换成patch后经过embedding变成[batch,num_patchs,dim]大小的数据</span></span><br></pre></td></tr></table></figure></li>
<li>forward如下：  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x = <span class="variable language_">self</span>.to_patch_embedding(img)<span class="comment">#img 按照切块儿的方式转换成embedding</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="2-2-数据embedding-post-embedding"><a href="#2-2-数据embedding-post-embedding" class="headerlink" title="2.2 数据embedding + post embedding"></a>2.2 数据embedding + post embedding</h2><ul>
<li><p>init</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">输入：              patch_1  patch_2  ...  patch_n</span><br><span class="line">                    ↓        ↓             ↓</span><br><span class="line">拼接：    [CLS]    patch_1  patch_2  ...  patch_n</span><br><span class="line">            ↓        ↓        ↓             ↓</span><br><span class="line">位置编码： +PE_0    +PE_1    +PE_2        +PE_n</span><br><span class="line">            ↓        ↓        ↓             ↓</span><br><span class="line">输入：  [CLS+PE_0, patch_1+PE_1, ..., patch_n+PE_n]</span><br><span class="line"></span><br><span class="line"><span class="variable language_">self</span>.pos_embedding = nn.Parameter(torch.randn(<span class="number">1</span>, num_patches + <span class="number">1</span>, dim)) <span class="comment">#+1，是因为还要加上一个 [CLS] token；dim通常为768</span></span><br><span class="line"><span class="variable language_">self</span>.cls_token = nn.Parameter(torch.randn(<span class="number">1</span>, <span class="number">1</span>, dim))<span class="comment">#这是 ViT 模仿 NLP 中 BERT 的做法，在最前面添加一个“全局摘要”用的 token。</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>forward如下：</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">b, n, _ = x.shape</span><br><span class="line"></span><br><span class="line">cls_tokens = repeat(<span class="variable language_">self</span>.cls_token, <span class="string">&#x27;1 1 d -&gt; b 1 d&#x27;</span>, b = b)</span><br><span class="line">x = torch.cat((cls_tokens, x), dim=<span class="number">1</span>) <span class="comment">#把 [CLS] token 拼接到每个图像 patch 序列的最前面。</span></span><br><span class="line">x += <span class="variable language_">self</span>.pos_embedding[:, :(n + <span class="number">1</span>)] <span class="comment">#给每个 patch + [CLS] token 加上对应的 位置编码；</span></span><br><span class="line">x = <span class="variable language_">self</span>.dropout(x) <span class="comment">#提高泛化能力，防止过拟合。</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="2-3-transformer"><a href="#2-3-transformer" class="headerlink" title="2.3 transformer"></a>2.3 transformer</h2><ul>
<li>transformer结构<ul>
<li><p><code>layers = [ (PreNorm(attn_1), PreNorm(ff_1)), (PreNorm(attn_2), PreNorm(ff_2)), ... ]   </code><br>这个是layer的结构，每个结构之前先过一个prenorm，<code>x = self.norm(x) return self.fn(x)</code><br>整体数据流如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">SequentialSequence：x = x + attn(x) x = x + ffn(x)</span><br><span class="line"><span class="built_in">input</span> x</span><br><span class="line">↓</span><br><span class="line">(attn_1 → ff_1) <span class="keyword">with</span> residual</span><br><span class="line">↓</span><br><span class="line">(attn_2 → ff_2)</span><br><span class="line">↓</span><br><span class="line">...</span><br><span class="line">↓</span><br><span class="line">(attn_n → ff_n)</span><br><span class="line">↓</span><br><span class="line">output</span><br><span class="line"></span><br><span class="line"><span class="comment">##树形数据流</span></span><br><span class="line">Transformer Block</span><br><span class="line">├── Multi-Head Attention</span><br><span class="line">│    └── Residual + LayerNorm</span><br><span class="line">├── FeedForward</span><br><span class="line">│    ├── Linear1 (dim → dim*<span class="number">4</span>)</span><br><span class="line">│    ├── GELU</span><br><span class="line">│    ├── Dropout</span><br><span class="line">│    ├── Linear2 (dim*<span class="number">4</span> → dim)</span><br><span class="line">│    └── Residual + LayerNorm</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Linformer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, seq_len, depth, k = <span class="number">256</span>, heads = <span class="number">8</span>, dim_head = <span class="literal">None</span>, one_kv_head = <span class="literal">False</span>, share_kv = <span class="literal">False</span>, reversible = <span class="literal">False</span>, dropout = <span class="number">0.</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        layers = nn.ModuleList([])</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(depth):</span><br><span class="line">            attn = LinformerSelfAttention(dim, seq_len, k = k, heads = heads, dim_head = dim_head, one_kv_head = one_kv_head, share_kv = share_kv, dropout = dropout)</span><br><span class="line">            ff = FeedForward(dim, dropout = dropout)</span><br><span class="line"></span><br><span class="line">            layers.append(nn.ModuleList([</span><br><span class="line">                PreNorm(dim, attn),</span><br><span class="line">                PreNorm(dim, ff)</span><br><span class="line">            ]))</span><br><span class="line"></span><br><span class="line">        execute_type = ReversibleSequence <span class="keyword">if</span> reversible <span class="keyword">else</span> SequentialSequence</span><br><span class="line">        <span class="variable language_">self</span>.net = execute_type(layers)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.net(x)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>attention结构<ul>
<li>linformer通过低秩空间的映射，使其从 O(n²) 降为 O(n·k)，其中 k ≪ n。主要结构为Proj_k。</li>
<li>linformer结构数据流如下：             <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">     ↓ to_q (Linear)</span><br><span class="line">Input x ───────────────→ Q</span><br><span class="line">      ↓ to_k/v (Linear)</span><br><span class="line">Input x ───────────────→ K, V → einsum(Proj_k/v) → K_proj, V_proj</span><br><span class="line">      ↓</span><br><span class="line"> Multi-head Attention</span><br><span class="line">      ↓</span><br><span class="line">   Output (Linear)</span><br></pre></td></tr></table></figure></li>
<li><code>self.proj_k = nn.Parameter(init_(torch.zeros(seq_len, k)))</code><br>proj_k: 是形状 [seq_len, k] 的 learnable 参数；<br>用于将原始 Key&#x2F;Value 沿着序列维度投影到更低维空间（线性投影矩阵）；也就是减少seq_len的维度</li>
<li>代码如下：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LinformerSelfAttention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, seq_len, k = <span class="number">256</span>, heads = <span class="number">8</span>, dim_head = <span class="literal">None</span>, one_kv_head = <span class="literal">False</span>, share_kv = <span class="literal">False</span>, dropout = <span class="number">0.</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="keyword">assert</span> (dim % heads) == <span class="number">0</span>, <span class="string">&#x27;dimension must be divisible by the number of heads&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.seq_len = seq_len</span><br><span class="line">        <span class="variable language_">self</span>.k = k</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.heads = heads</span><br><span class="line"></span><br><span class="line">        dim_head = default(dim_head, dim // heads)</span><br><span class="line">        <span class="variable language_">self</span>.dim_head = dim_head</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.to_q = nn.Linear(dim, dim_head * heads, bias = <span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        kv_dim = dim_head <span class="keyword">if</span> one_kv_head <span class="keyword">else</span> (dim_head * heads)</span><br><span class="line">        <span class="variable language_">self</span>.to_k = nn.Linear(dim, kv_dim, bias = <span class="literal">False</span>)</span><br><span class="line">        <span class="variable language_">self</span>.proj_k = nn.Parameter(init_(torch.zeros(seq_len, k)))</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.share_kv = share_kv</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> share_kv:</span><br><span class="line">            <span class="variable language_">self</span>.to_v = nn.Linear(dim, kv_dim, bias = <span class="literal">False</span>)</span><br><span class="line">            <span class="variable language_">self</span>.proj_v = nn.Parameter(init_(torch.zeros(seq_len, k)))</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.dropout = nn.Dropout(dropout)</span><br><span class="line">        <span class="variable language_">self</span>.to_out = nn.Linear(dim_head * heads, dim)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, context = <span class="literal">None</span>, **kwargs</span>):</span><br><span class="line">        b, n, d, d_h, h, k = *x.shape, <span class="variable language_">self</span>.dim_head, <span class="variable language_">self</span>.heads, <span class="variable language_">self</span>.k</span><br><span class="line"></span><br><span class="line">        kv_len = n <span class="keyword">if</span> context <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> context.shape[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">assert</span> kv_len &lt;= <span class="variable language_">self</span>.seq_len, <span class="string">f&#x27;the sequence length of the key / values must be <span class="subst">&#123;self.seq_len&#125;</span> - <span class="subst">&#123;kv_len&#125;</span> given&#x27;</span></span><br><span class="line"></span><br><span class="line">        queries = <span class="variable language_">self</span>.to_q(x)</span><br><span class="line"></span><br><span class="line">        proj_seq_len = <span class="keyword">lambda</span> args: torch.einsum(<span class="string">&#x27;bnd,nk-&gt;bkd&#x27;</span>, *args)</span><br><span class="line"></span><br><span class="line">        kv_input = x <span class="keyword">if</span> context <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> context</span><br><span class="line"></span><br><span class="line">        keys = <span class="variable language_">self</span>.to_k(kv_input)</span><br><span class="line">        values = <span class="variable language_">self</span>.to_v(kv_input) <span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.share_kv <span class="keyword">else</span> keys</span><br><span class="line"></span><br><span class="line">        kv_projs = (<span class="variable language_">self</span>.proj_k, <span class="variable language_">self</span>.proj_v <span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.share_kv <span class="keyword">else</span> <span class="variable language_">self</span>.proj_k)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># allow for variable sequence lengths (less than maximum sequence length) by slicing projections</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> kv_len &lt; <span class="variable language_">self</span>.seq_len:</span><br><span class="line">            kv_projs = <span class="built_in">map</span>(<span class="keyword">lambda</span> t: t[:kv_len], kv_projs)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># project keys and values along the sequence length dimension to k</span></span><br><span class="line">        <span class="comment"># 对 key/value 做低秩投影</span></span><br><span class="line">        keys, values = <span class="built_in">map</span>(proj_seq_len, <span class="built_in">zip</span>((keys, values), kv_projs))<span class="comment">#map(功能，输入) zip()-&gt;（k，proj_k）（v,proj_v）</span></span><br><span class="line">        <span class="comment">#[b,k,d][b,k,d]</span></span><br><span class="line">        <span class="comment"># merge head into batch for queries and key / values</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># queries → reshape + transpose → [b, h, n, d_h]</span></span><br><span class="line">        <span class="comment"># keys/values → reshape → [b, h, k, d_h]</span></span><br><span class="line">        queries = queries.reshape(b, n, h, -<span class="number">1</span>).transpose(<span class="number">1</span>, <span class="number">2</span>)<span class="comment">#[b,n,d]-&gt;[b,n,h,h_d]-&gt;[b,h,n,h_d]</span></span><br><span class="line"></span><br><span class="line">        merge_key_values = <span class="keyword">lambda</span> t: t.reshape(b, k, -<span class="number">1</span>, d_h).transpose(<span class="number">1</span>, <span class="number">2</span>).expand(-<span class="number">1</span>, h, -<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">        keys, values = <span class="built_in">map</span>(merge_key_values, (keys, values)) <span class="comment">#map(功能，输入)[b,k,d]-&gt;[b,k,h,h_d]-&gt;[b,h,k,h_d]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># attention</span></span><br><span class="line"></span><br><span class="line">        dots = torch.einsum(<span class="string">&#x27;bhnd,bhkd-&gt;bhnk&#x27;</span>, queries, keys) * (d_h ** -<span class="number">0.5</span>) <span class="comment">#复杂度是nkd，flops=每个位置是一个向量点乘，每个位置需要 d_h 次乘加，一共b*n*h个位置，所以是2dhnkd</span></span><br><span class="line">        attn = dots.softmax(dim=-<span class="number">1</span>)</span><br><span class="line">        attn = <span class="variable language_">self</span>.dropout(attn)</span><br><span class="line">        out = torch.einsum(<span class="string">&#x27;bhnk,bhkd-&gt;bhnd&#x27;</span>, attn, values)<span class="comment">#复杂度是ndk，flops是b*h*n*d个位置，每个位置k次乘加，所以是2dhnkd</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># split heads</span></span><br><span class="line">        out = out.transpose(<span class="number">1</span>, <span class="number">2</span>).reshape(b, n, -<span class="number">1</span>)<span class="comment">#bhnd_n-&gt;bnhd_n-&gt;bnd</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.to_out(out)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>ffn结构（feedforward）<ul>
<li><p>两层 Linear + 激活 + Dropout</p>
</li>
<li><p>引入门控机制GLU： <code>act(x) * v  也就是  GELU(x)*v</code></p>
</li>
<li><p>gelu的原理：<br>$<br>\text{GELU}(x) &#x3D; x \cdot \Phi(x)<br>$<br>标准正态分布的累积分布函数的近似实现：<br>$\text{GELU}(x) \approx 0.5 \cdot x \cdot \left(1 + \tanh\left( \sqrt{\frac{2}{\pi}} \cdot (x + 0.044715 x^3) \right) \right)$<br>实现了 高斯概率加权的 x（相当于柔和过渡）</p>
</li>
<li><p>数据流如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##正常版本数据流</span></span><br><span class="line">x → Linear(dim, dim*<span class="number">4</span>) [B, L, D][B, L, D*<span class="number">4</span>] 扩大特征维度</span><br><span class="line">    → GELU / ReLU / SiLU [B, L, D*<span class="number">4</span>][B, L, D*<span class="number">4</span>] 非线性变换</span><br><span class="line">    → Dropout [B, L, D*<span class="number">4</span>][B, L, D*<span class="number">4</span>] 正则化</span><br><span class="line">    → Linear(dim*<span class="number">4</span>, dim) [B, L, D*<span class="number">4</span>][B, L, D] 映射回原始维度</span><br><span class="line">    → Residual + LayerNorm</span><br><span class="line"><span class="comment">#GLU版本数据流</span></span><br><span class="line">x → Linear(dim, dim*<span class="number">8</span>)  → chunk 成 x1, x2</span><br><span class="line">    x1 → 激活(x1)</span><br><span class="line">    out = x1 * x2 <span class="comment">#GLU</span></span><br><span class="line">    → Dropout → Linear(dim*<span class="number">4</span>, dim)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GELU_</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.5</span> * x * (<span class="number">1</span> + torch.tanh(math.sqrt(<span class="number">2</span> / math.pi) * (x + <span class="number">0.044715</span> * torch.<span class="built_in">pow</span>(x, <span class="number">3</span>))))</span><br><span class="line"></span><br><span class="line">GELU = nn.GELU <span class="keyword">if</span> <span class="built_in">hasattr</span>(nn, <span class="string">&#x27;GELU&#x27;</span>) <span class="keyword">else</span> GELU_</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FeedForward</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, mult = <span class="number">4</span>, dropout = <span class="number">0.</span>, activation = <span class="literal">None</span>, glu = <span class="literal">False</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        activation = default(activation, GELU)</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.glu = glu</span><br><span class="line">        <span class="variable language_">self</span>.w1 = nn.Linear(dim, dim * mult * (<span class="number">2</span> <span class="keyword">if</span> glu <span class="keyword">else</span> <span class="number">1</span>))</span><br><span class="line">        <span class="variable language_">self</span>.act = activation()</span><br><span class="line">        <span class="variable language_">self</span>.dropout = nn.Dropout(dropout)</span><br><span class="line">        <span class="variable language_">self</span>.w2 = nn.Linear(dim * mult, dim)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, **kwargs</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.glu:</span><br><span class="line">            x = <span class="variable language_">self</span>.w1(x)</span><br><span class="line">            x = <span class="variable language_">self</span>.act(x)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            x, v = <span class="variable language_">self</span>.w1(x).chunk(<span class="number">2</span>, dim=-<span class="number">1</span>)</span><br><span class="line">            x = <span class="variable language_">self</span>.act(x) * v</span><br><span class="line"></span><br><span class="line">        x = <span class="variable language_">self</span>.dropout(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.w2(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<h2 id="2-4-分类输出"><a href="#2-4-分类输出" class="headerlink" title="2.4 分类输出"></a>2.4 分类输出</h2><ul>
<li>forward部分如下：  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通常 [CLS] token 最后用于做分类任务的输出 head（类似 BERT）。</span></span><br><span class="line">x = x.mean(dim = <span class="number">1</span>) <span class="keyword">if</span> <span class="variable language_">self</span>.pool == <span class="string">&#x27;mean&#x27;</span> <span class="keyword">else</span> x[:, <span class="number">0</span>] <span class="comment">#对所有 token（包括 patch 和 CLS）取平均；</span></span><br><span class="line"><span class="comment"># 否则取 [CLS] token，即 x[:, 0]；</span></span><br><span class="line"></span><br><span class="line">x = <span class="variable language_">self</span>.to_latent(x)</span><br><span class="line">out = <span class="variable language_">self</span>.mlp_head(x)</span><br><span class="line"><span class="keyword">return</span> out</span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="3-onnx导出"><a href="#3-onnx导出" class="headerlink" title="3.onnx导出"></a>3.onnx导出</h1><ul>
<li>onnx导出只需要在example加载原来保存的模型，然后导出。  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ✅ 6. 导出 ONNX 模型</span></span><br><span class="line">model.load_state_dict(torch.load(<span class="string">&quot;model/best_model_vit.pth&quot;</span>, map_location=<span class="string">&quot;cpu&quot;</span>))  <span class="comment"># 替换为你的路径</span></span><br><span class="line">dummy_input = torch.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>).to(device)</span><br><span class="line">model.to(device).<span class="built_in">eval</span>()</span><br><span class="line">torch.onnx.export(</span><br><span class="line">    model.module <span class="keyword">if</span> <span class="built_in">isinstance</span>(model, nn.DataParallel) <span class="keyword">else</span> model,</span><br><span class="line">    dummy_input,</span><br><span class="line">    <span class="string">&quot;model/final_model_vit.onnx&quot;</span>,</span><br><span class="line">    input_names=[<span class="string">&quot;input&quot;</span>],</span><br><span class="line">    output_names=[<span class="string">&quot;output&quot;</span>],</span><br><span class="line">    opset_version=<span class="number">16</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<ul>
<li>可以用netron查看模型结构。<br><img src="/./jpg/onnx-vit.jpg" alt="vit-onnx"></li>
</ul>
</li>
</ul>
<h1 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h1><ul>
<li>tensorrt编译测速</li>
<li>profiling分析</li>
<li>自定义layernorm</li>
<li>量化精度分析</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/07/27/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/vit%E6%BA%90%E7%A0%81%E8%AF%A6%E8%A7%A3/" data-id="cmdwxao65000i5ox9fzde1l9x" data-title="vit源码详解(linformer)" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Transformer/" rel="tag">Transformer</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/linformer/" rel="tag">linformer</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/vit/" rel="tag">vit</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/vit-pytorch/" rel="tag">vit-pytorch</a></li></ul>

    </footer>
  </div>
  
</article>



  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="page-number current">2</span>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/markdown/">markdown</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%91%A8%E8%AE%A1%E5%88%92/">周计划</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/">基础知识</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F/">推理加速</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/FLOPS/" rel="tag">FLOPS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Transformer/" rel="tag">Transformer</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/attention/" rel="tag">attention</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/conv/" rel="tag">conv</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cuda%E5%8A%A0%E9%80%9F/" rel="tag">cuda加速</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/float/" rel="tag">float</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/img-preprocess/" rel="tag">img_preprocess</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/int/" rel="tag">int</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kv-cache/" rel="tag">kv-cache</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linformer/" rel="tag">linformer</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/profiling/" rel="tag">profiling</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/vit/" rel="tag">vit</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/vit-pytorch/" rel="tag">vit-pytorch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/week1/" rel="tag">week1</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AE%9A%E7%82%B9%E6%95%B0/" rel="tag">定点数</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%B0%8F%E6%8A%80%E5%B7%A7/" rel="tag">小技巧</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8/" rel="tag">显存占用</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B5%AE%E7%82%B9%E6%95%B0/" rel="tag">浮点数</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%AE%97%E6%B3%95%E5%A4%8D%E6%9D%82%E5%BA%A6/" rel="tag">算法复杂度</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%BF%90%E7%AE%97%E9%87%8F/" rel="tag">运算量</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/FLOPS/" style="font-size: 10px;">FLOPS</a> <a href="/tags/Transformer/" style="font-size: 10px;">Transformer</a> <a href="/tags/attention/" style="font-size: 20px;">attention</a> <a href="/tags/conv/" style="font-size: 10px;">conv</a> <a href="/tags/cuda%E5%8A%A0%E9%80%9F/" style="font-size: 20px;">cuda加速</a> <a href="/tags/float/" style="font-size: 10px;">float</a> <a href="/tags/img-preprocess/" style="font-size: 10px;">img_preprocess</a> <a href="/tags/int/" style="font-size: 10px;">int</a> <a href="/tags/kv-cache/" style="font-size: 10px;">kv-cache</a> <a href="/tags/linformer/" style="font-size: 10px;">linformer</a> <a href="/tags/profiling/" style="font-size: 10px;">profiling</a> <a href="/tags/vit/" style="font-size: 20px;">vit</a> <a href="/tags/vit-pytorch/" style="font-size: 20px;">vit-pytorch</a> <a href="/tags/week1/" style="font-size: 10px;">week1</a> <a href="/tags/%E5%AE%9A%E7%82%B9%E6%95%B0/" style="font-size: 10px;">定点数</a> <a href="/tags/%E5%B0%8F%E6%8A%80%E5%B7%A7/" style="font-size: 10px;">小技巧</a> <a href="/tags/%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8/" style="font-size: 10px;">显存占用</a> <a href="/tags/%E6%B5%AE%E7%82%B9%E6%95%B0/" style="font-size: 10px;">浮点数</a> <a href="/tags/%E7%AE%97%E6%B3%95%E5%A4%8D%E6%9D%82%E5%BA%A6/" style="font-size: 10px;">算法复杂度</a> <a href="/tags/%E8%BF%90%E7%AE%97%E9%87%8F/" style="font-size: 10px;">运算量</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/07/">July 2025</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2025/07/31/%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F/kvcache/">kv-cache-源码解读</a>
          </li>
        
          <li>
            <a href="/2025/07/31/tensorrt-plugin/">tensorrt-plugin</a>
          </li>
        
          <li>
            <a href="/2025/07/31/%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F/cuda%E4%BC%98%E5%8C%96%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/">resize_cuda</a>
          </li>
        
          <li>
            <a href="/2025/07/31/%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F/resize-cuda/">resize_cuda</a>
          </li>
        
          <li>
            <a href="/2025/07/30/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%84%9F%E7%9F%A5%E9%A2%84%E5%A4%84%E7%90%86/">img_preproc</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2025 sunhanyu<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>